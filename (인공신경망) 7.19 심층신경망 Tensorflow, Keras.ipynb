{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package tensorflow.python.keras.api._v1.keras in tensorflow.python.keras.api._v1:\n",
      "\n",
      "NAME\n",
      "    tensorflow.python.keras.api._v1.keras\n",
      "\n",
      "DESCRIPTION\n",
      "    # This file is MACHINE GENERATED! Do not edit.\n",
      "    # Generated by: tensorflow/python/tools/api/generator/create_python_api.py script.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    activations (package)\n",
      "    applications (package)\n",
      "    backend (package)\n",
      "    callbacks (package)\n",
      "    constraints (package)\n",
      "    datasets (package)\n",
      "    estimator (package)\n",
      "    experimental (package)\n",
      "    initializers (package)\n",
      "    layers (package)\n",
      "    losses (package)\n",
      "    metrics (package)\n",
      "    mixed_precision (package)\n",
      "    models (package)\n",
      "    optimizers (package)\n",
      "    preprocessing (package)\n",
      "    regularizers (package)\n",
      "    utils (package)\n",
      "    wrappers (package)\n",
      "\n",
      "CLASSES\n",
      "    tensorflow.python.keras.engine.network.Network(tensorflow.python.keras.engine.base_layer.Layer)\n",
      "        tensorflow.python.keras.engine.training.Model\n",
      "            tensorflow.python.keras.engine.sequential.Sequential\n",
      "    \n",
      "    class Model(tensorflow.python.keras.engine.network.Network)\n",
      "     |  Model(*args, **kwargs)\n",
      "     |  \n",
      "     |  `Model` groups layers into an object with training and inference features.\n",
      "     |  \n",
      "     |  There are two ways to instantiate a `Model`:\n",
      "     |  \n",
      "     |  1 - With the \"functional API\", where you start from `Input`,\n",
      "     |  you chain layer calls to specify the model's forward pass,\n",
      "     |  and finally you create your model from inputs and outputs:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  import tensorflow as tf\n",
      "     |  \n",
      "     |  inputs = tf.keras.Input(shape=(3,))\n",
      "     |  x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
      "     |  outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
      "     |  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  2 - By subclassing the `Model` class: in that case, you should define your\n",
      "     |  layers in `__init__` and you should implement the model's forward pass\n",
      "     |  in `call`.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  import tensorflow as tf\n",
      "     |  \n",
      "     |  class MyModel(tf.keras.Model):\n",
      "     |  \n",
      "     |    def __init__(self):\n",
      "     |      super(MyModel, self).__init__()\n",
      "     |      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
      "     |      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
      "     |  \n",
      "     |    def call(self, inputs):\n",
      "     |      x = self.dense1(inputs)\n",
      "     |      return self.dense2(x)\n",
      "     |  \n",
      "     |  model = MyModel()\n",
      "     |  ```\n",
      "     |  \n",
      "     |  If you subclass `Model`, you can optionally have\n",
      "     |  a `training` argument (boolean) in `call`, which you can use to specify\n",
      "     |  a different behavior in training and inference:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  import tensorflow as tf\n",
      "     |  \n",
      "     |  class MyModel(tf.keras.Model):\n",
      "     |  \n",
      "     |    def __init__(self):\n",
      "     |      super(MyModel, self).__init__()\n",
      "     |      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
      "     |      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
      "     |      self.dropout = tf.keras.layers.Dropout(0.5)\n",
      "     |  \n",
      "     |    def call(self, inputs, training=False):\n",
      "     |      x = self.dense1(inputs)\n",
      "     |      if training:\n",
      "     |        x = self.dropout(x, training=training)\n",
      "     |      return self.dense2(x)\n",
      "     |  \n",
      "     |  model = MyModel()\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Model\n",
      "     |      tensorflow.python.keras.engine.network.Network\n",
      "     |      tensorflow.python.keras.engine.base_layer.Layer\n",
      "     |      tensorflow.python.module.module.Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, distribute=None, **kwargs)\n",
      "     |      Configures the model for training.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          optimizer: String (name of optimizer) or optimizer instance.\n",
      "     |              See `tf.keras.optimizers`.\n",
      "     |          loss: String (name of objective function), objective function or\n",
      "     |              `tf.losses.Loss` instance. See `tf.losses`. If the model has\n",
      "     |              multiple outputs, you can use a different loss on each output by\n",
      "     |              passing a dictionary or a list of losses. The loss value that will\n",
      "     |              be minimized by the model will then be the sum of all individual\n",
      "     |              losses.\n",
      "     |          metrics: List of metrics to be evaluated by the model during training\n",
      "     |              and testing. Typically you will use `metrics=['accuracy']`.\n",
      "     |              To specify different metrics for different outputs of a\n",
      "     |              multi-output model, you could also pass a dictionary, such as\n",
      "     |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      "     |              You can also pass a list (len = len(outputs)) of lists of metrics\n",
      "     |              such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      "     |              `metrics=['accuracy', ['accuracy', 'mse']]`.\n",
      "     |          loss_weights: Optional list or dictionary specifying scalar\n",
      "     |              coefficients (Python floats) to weight the loss contributions\n",
      "     |              of different model outputs.\n",
      "     |              The loss value that will be minimized by the model\n",
      "     |              will then be the *weighted sum* of all individual losses,\n",
      "     |              weighted by the `loss_weights` coefficients.\n",
      "     |              If a list, it is expected to have a 1:1 mapping\n",
      "     |              to the model's outputs. If a tensor, it is expected to map\n",
      "     |              output names (strings) to scalar coefficients.\n",
      "     |          sample_weight_mode: If you need to do timestep-wise\n",
      "     |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      "     |              `None` defaults to sample-wise weights (1D).\n",
      "     |              If the model has multiple outputs, you can use a different\n",
      "     |              `sample_weight_mode` on each output by passing a\n",
      "     |              dictionary or a list of modes.\n",
      "     |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      "     |              by sample_weight or class_weight during training and testing.\n",
      "     |          target_tensors: By default, Keras will create placeholders for the\n",
      "     |              model's target, which will be fed with the target data during\n",
      "     |              training. If instead you would like to use your own\n",
      "     |              target tensors (in turn, Keras will not expect external\n",
      "     |              Numpy data for these targets at training time), you\n",
      "     |              can specify them via the `target_tensors` argument. It can be\n",
      "     |              a single tensor (for a single-output model), a list of tensors,\n",
      "     |              or a dict mapping output names to target tensors.\n",
      "     |          distribute: NOT SUPPORTED IN TF 2.0, please create and compile the\n",
      "     |              model under distribution strategy scope instead of passing it to\n",
      "     |              compile.\n",
      "     |          **kwargs: Any additional arguments.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of invalid arguments for\n",
      "     |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      "     |  \n",
      "     |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      "     |      Returns the loss value & metrics values for the model in test mode.\n",
      "     |      \n",
      "     |      Computation is done in batches.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input data. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A dict mapping input names to the corresponding array/tensors,\n",
      "     |              if the model has named inputs.\n",
      "     |            - A `tf.data` dataset or a dataset iterator.\n",
      "     |            - A generator or `keras.utils.Sequence` instance.\n",
      "     |          y: Target data. Like the input data `x`,\n",
      "     |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "     |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "     |            tensor targets, or inversely).\n",
      "     |            If `x` is a dataset, dataset iterator, generator or\n",
      "     |            `keras.utils.Sequence` instance, `y` should not be specified (since\n",
      "     |            targets will be obtained from the iterator/dataset).\n",
      "     |          batch_size: Integer or `None`.\n",
      "     |              Number of samples per gradient update.\n",
      "     |              If unspecified, `batch_size` will default to 32.\n",
      "     |              Do not specify the `batch_size` is your data is in the\n",
      "     |              form of symbolic tensors, dataset, dataset iterators,\n",
      "     |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      "     |              batches).\n",
      "     |          verbose: 0 or 1. Verbosity mode.\n",
      "     |              0 = silent, 1 = progress bar.\n",
      "     |          sample_weight: Optional Numpy array of weights for\n",
      "     |              the test samples, used for weighting the loss function.\n",
      "     |              You can either pass a flat (1D)\n",
      "     |              Numpy array with the same length as the input samples\n",
      "     |              (1:1 mapping between weights and samples),\n",
      "     |              or in the case of temporal data,\n",
      "     |              you can pass a 2D array with shape\n",
      "     |              `(samples, sequence_length)`,\n",
      "     |              to apply a different weight to every timestep of every sample.\n",
      "     |              In this case you should make sure to specify\n",
      "     |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      "     |              supported when `x` is a dataset or a dataset iterator, instead pass\n",
      "     |              sample weights as the third element of `x`.\n",
      "     |          steps: Integer or `None`.\n",
      "     |              Total number of steps (batches of samples)\n",
      "     |              before declaring the evaluation round finished.\n",
      "     |              Ignored with the default value of `None`.\n",
      "     |              If x is a `tf.data` dataset or a dataset iterator, and `steps` is\n",
      "     |              None, 'evaluate' will run until the dataset is exhausted.\n",
      "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      "     |              List of callbacks to apply during evaluation.\n",
      "     |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "     |              input only. Maximum size for the generator queue.\n",
      "     |              If unspecified, `max_queue_size` will default to 10.\n",
      "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "     |              only. Maximum number of processes to spin up when using\n",
      "     |              process-based threading. If unspecified, `workers` will default\n",
      "     |              to 1. If 0, will execute the generator on the main thread.\n",
      "     |          use_multiprocessing: Boolean. Used for generator or\n",
      "     |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "     |              threading. If unspecified, `use_multiprocessing` will default to\n",
      "     |              `False`. Note that because this implementation relies on\n",
      "     |              multiprocessing, you should not pass non-picklable arguments to\n",
      "     |              the generator as they can't be passed easily to children processes.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Scalar test loss (if the model has a single output and no metrics)\n",
      "     |          or list of scalars (if the model has multiple outputs\n",
      "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      "     |          the display labels for the scalar outputs.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: in case of invalid arguments.\n",
      "     |  \n",
      "     |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      "     |      Evaluates the model on a data generator.\n",
      "     |      \n",
      "     |      The generator should return the same kind of data\n",
      "     |      as accepted by `test_on_batch`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          generator: Generator yielding tuples (inputs, targets)\n",
      "     |              or (inputs, targets, sample_weights)\n",
      "     |              or an instance of `keras.utils.Sequence`\n",
      "     |              object in order to avoid duplicate data\n",
      "     |              when using multiprocessing.\n",
      "     |          steps: Total number of steps (batches of samples)\n",
      "     |              to yield from `generator` before stopping.\n",
      "     |              Optional for `Sequence`: if unspecified, will use\n",
      "     |              the `len(generator)` as a number of steps.\n",
      "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      "     |              List of callbacks to apply during evaluation.\n",
      "     |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      "     |          max_queue_size: maximum size for the generator queue\n",
      "     |          workers: Integer. Maximum number of processes to spin up\n",
      "     |              when using process-based threading.\n",
      "     |              If unspecified, `workers` will default to 1. If 0, will\n",
      "     |              execute the generator on the main thread.\n",
      "     |          use_multiprocessing: Boolean.\n",
      "     |              If `True`, use process-based threading.\n",
      "     |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      "     |              Note that because this implementation relies on multiprocessing,\n",
      "     |              you should not pass non-picklable arguments to the generator\n",
      "     |              as they can't be passed easily to children processes.\n",
      "     |          verbose: Verbosity mode, 0 or 1.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Scalar test loss (if the model has a single output and no metrics)\n",
      "     |          or list of scalars (if the model has multiple outputs\n",
      "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      "     |          the display labels for the scalar outputs.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: in case of invalid arguments.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case the generator yields data in an invalid format.\n",
      "     |  \n",
      "     |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs)\n",
      "     |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input data. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A dict mapping input names to the corresponding array/tensors,\n",
      "     |              if the model has named inputs.\n",
      "     |            - A `tf.data` dataset or a dataset iterator. Should return a tuple\n",
      "     |              of either `(inputs, targets)` or\n",
      "     |              `(inputs, targets, sample_weights)`.\n",
      "     |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      "     |              or `(inputs, targets, sample weights)`.\n",
      "     |          y: Target data. Like the input data `x`,\n",
      "     |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "     |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "     |            tensor targets, or inversely). If `x` is a dataset, dataset\n",
      "     |            iterator, generator, or `keras.utils.Sequence` instance, `y` should\n",
      "     |            not be specified (since targets will be obtained from `x`).\n",
      "     |          batch_size: Integer or `None`.\n",
      "     |              Number of samples per gradient update.\n",
      "     |              If unspecified, `batch_size` will default to 32.\n",
      "     |              Do not specify the `batch_size` if your data is in the\n",
      "     |              form of symbolic tensors, dataset, dataset iterators,\n",
      "     |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      "     |              batches).\n",
      "     |          epochs: Integer. Number of epochs to train the model.\n",
      "     |              An epoch is an iteration over the entire `x` and `y`\n",
      "     |              data provided.\n",
      "     |              Note that in conjunction with `initial_epoch`,\n",
      "     |              `epochs` is to be understood as \"final epoch\".\n",
      "     |              The model is not trained for a number of iterations\n",
      "     |              given by `epochs`, but merely until the epoch\n",
      "     |              of index `epochs` is reached.\n",
      "     |          verbose: 0, 1, or 2. Verbosity mode.\n",
      "     |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "     |              Note that the progress bar is not particularly useful when\n",
      "     |              logged to a file, so verbose=2 is recommended when not running\n",
      "     |              interactively (eg, in a production environment).\n",
      "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      "     |              List of callbacks to apply during training.\n",
      "     |              See `tf.keras.callbacks`.\n",
      "     |          validation_split: Float between 0 and 1.\n",
      "     |              Fraction of the training data to be used as validation data.\n",
      "     |              The model will set apart this fraction of the training data,\n",
      "     |              will not train on it, and will evaluate\n",
      "     |              the loss and any model metrics\n",
      "     |              on this data at the end of each epoch.\n",
      "     |              The validation data is selected from the last samples\n",
      "     |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      "     |              not supported when `x` is a dataset, dataset iterator, generator or\n",
      "     |             `keras.utils.Sequence` instance.\n",
      "     |          validation_data: Data on which to evaluate\n",
      "     |              the loss and any model metrics at the end of each epoch.\n",
      "     |              The model will not be trained on this data.\n",
      "     |              `validation_data` will override `validation_split`.\n",
      "     |              `validation_data` could be:\n",
      "     |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      "     |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      "     |                - dataset or a dataset iterator\n",
      "     |              For the first two cases, `batch_size` must be provided.\n",
      "     |              For the last case, `validation_steps` must be provided.\n",
      "     |          shuffle: Boolean (whether to shuffle the training data\n",
      "     |              before each epoch) or str (for 'batch').\n",
      "     |              'batch' is a special option for dealing with the\n",
      "     |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      "     |              Has no effect when `steps_per_epoch` is not `None`.\n",
      "     |          class_weight: Optional dictionary mapping class indices (integers)\n",
      "     |              to a weight (float) value, used for weighting the loss function\n",
      "     |              (during training only).\n",
      "     |              This can be useful to tell the model to\n",
      "     |              \"pay more attention\" to samples from\n",
      "     |              an under-represented class.\n",
      "     |          sample_weight: Optional Numpy array of weights for\n",
      "     |              the training samples, used for weighting the loss function\n",
      "     |              (during training only). You can either pass a flat (1D)\n",
      "     |              Numpy array with the same length as the input samples\n",
      "     |              (1:1 mapping between weights and samples),\n",
      "     |              or in the case of temporal data,\n",
      "     |              you can pass a 2D array with shape\n",
      "     |              `(samples, sequence_length)`,\n",
      "     |              to apply a different weight to every timestep of every sample.\n",
      "     |              In this case you should make sure to specify\n",
      "     |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      "     |              supported when `x` is a dataset, dataset iterator, generator, or\n",
      "     |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      "     |              as the third element of `x`.\n",
      "     |          initial_epoch: Integer.\n",
      "     |              Epoch at which to start training\n",
      "     |              (useful for resuming a previous training run).\n",
      "     |          steps_per_epoch: Integer or `None`.\n",
      "     |              Total number of steps (batches of samples)\n",
      "     |              before declaring one epoch finished and starting the\n",
      "     |              next epoch. When training with input tensors such as\n",
      "     |              TensorFlow data tensors, the default `None` is equal to\n",
      "     |              the number of samples in your dataset divided by\n",
      "     |              the batch size, or 1 if that cannot be determined. If x is a\n",
      "     |              `tf.data` dataset or a dataset iterator, and 'steps_per_epoch'\n",
      "     |              is None, the epoch will run until the input dataset is exhausted.\n",
      "     |          validation_steps: Only relevant if `validation_data` is provided and\n",
      "     |              is a dataset or dataset iterator. Total number of steps (batches of\n",
      "     |              samples) to draw before stopping when performing validation\n",
      "     |              at the end of every epoch. If validation_data is a `tf.data` dataset\n",
      "     |              or a dataset iterator, and 'validation_steps' is None, validation\n",
      "     |              will run until the `validation_data` dataset is exhausted.\n",
      "     |          validation_freq: Only relevant if validation data is provided. Integer\n",
      "     |              or `collections.Container` instance (e.g. list, tuple, etc.). If an\n",
      "     |              integer, specifies how many training epochs to run before a new\n",
      "     |              validation run is performed, e.g. `validation_freq=2` runs\n",
      "     |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      "     |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      "     |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "     |              input only. Maximum size for the generator queue.\n",
      "     |              If unspecified, `max_queue_size` will default to 10.\n",
      "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "     |              only. Maximum number of processes to spin up\n",
      "     |              when using process-based threading. If unspecified, `workers`\n",
      "     |              will default to 1. If 0, will execute the generator on the main\n",
      "     |              thread.\n",
      "     |          use_multiprocessing: Boolean. Used for generator or\n",
      "     |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "     |              threading. If unspecified, `use_multiprocessing` will default to\n",
      "     |              `False`. Note that because this implementation relies on\n",
      "     |              multiprocessing, you should not pass non-picklable arguments to\n",
      "     |              the generator as they can't be passed easily to children processes.\n",
      "     |          **kwargs: Used for backwards compatibility.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A `History` object. Its `History.history` attribute is\n",
      "     |          a record of training loss values and metrics values\n",
      "     |          at successive epochs, as well as validation loss values\n",
      "     |          and validation metrics values (if applicable).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          RuntimeError: If the model was never compiled.\n",
      "     |          ValueError: In case of mismatch between the provided input data\n",
      "     |              and what the model expects.\n",
      "     |  \n",
      "     |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      "     |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      "     |      \n",
      "     |      The generator is run in parallel to the model, for efficiency.\n",
      "     |      For instance, this allows you to do real-time data augmentation\n",
      "     |      on images on CPU in parallel to training your model on GPU.\n",
      "     |      \n",
      "     |      The use of `keras.utils.Sequence` guarantees the ordering\n",
      "     |      and guarantees the single use of every input per epoch when\n",
      "     |      using `use_multiprocessing=True`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          generator: A generator or an instance of `Sequence`\n",
      "     |            (`keras.utils.Sequence`)\n",
      "     |              object in order to avoid duplicate data\n",
      "     |              when using multiprocessing.\n",
      "     |              The output of the generator must be either\n",
      "     |              - a tuple `(inputs, targets)`\n",
      "     |              - a tuple `(inputs, targets, sample_weights)`.\n",
      "     |              This tuple (a single output of the generator) makes a single batch.\n",
      "     |              Therefore, all arrays in this tuple must have the same length (equal\n",
      "     |              to the size of this batch). Different batches may have different\n",
      "     |                sizes.\n",
      "     |              For example, the last batch of the epoch is commonly smaller than\n",
      "     |                the\n",
      "     |              others, if the size of the dataset is not divisible by the batch\n",
      "     |                size.\n",
      "     |              The generator is expected to loop over its data\n",
      "     |              indefinitely. An epoch finishes when `steps_per_epoch`\n",
      "     |              batches have been seen by the model.\n",
      "     |          steps_per_epoch: Total number of steps (batches of samples)\n",
      "     |              to yield from `generator` before declaring one epoch\n",
      "     |              finished and starting the next epoch. It should typically\n",
      "     |              be equal to the number of samples of your dataset\n",
      "     |              divided by the batch size.\n",
      "     |              Optional for `Sequence`: if unspecified, will use\n",
      "     |              the `len(generator)` as a number of steps.\n",
      "     |          epochs: Integer, total number of iterations on the data.\n",
      "     |          verbose: Verbosity mode, 0, 1, or 2.\n",
      "     |          callbacks: List of callbacks to be called during training.\n",
      "     |          validation_data: This can be either\n",
      "     |              - a generator for the validation data\n",
      "     |              - a tuple (inputs, targets)\n",
      "     |              - a tuple (inputs, targets, sample_weights).\n",
      "     |          validation_steps: Only relevant if `validation_data`\n",
      "     |              is a generator. Total number of steps (batches of samples)\n",
      "     |              to yield from `generator` before stopping.\n",
      "     |              Optional for `Sequence`: if unspecified, will use\n",
      "     |              the `len(validation_data)` as a number of steps.\n",
      "     |          validation_freq: Only relevant if validation data is provided. Integer\n",
      "     |              or `collections.Container` instance (e.g. list, tuple, etc.). If an\n",
      "     |              integer, specifies how many training epochs to run before a new\n",
      "     |              validation run is performed, e.g. `validation_freq=2` runs\n",
      "     |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      "     |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      "     |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      "     |          class_weight: Dictionary mapping class indices to a weight\n",
      "     |              for the class.\n",
      "     |          max_queue_size: Integer. Maximum size for the generator queue.\n",
      "     |              If unspecified, `max_queue_size` will default to 10.\n",
      "     |          workers: Integer. Maximum number of processes to spin up\n",
      "     |              when using process-based threading.\n",
      "     |              If unspecified, `workers` will default to 1. If 0, will\n",
      "     |              execute the generator on the main thread.\n",
      "     |          use_multiprocessing: Boolean.\n",
      "     |              If `True`, use process-based threading.\n",
      "     |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      "     |              Note that because this implementation relies on multiprocessing,\n",
      "     |              you should not pass non-picklable arguments to the generator\n",
      "     |              as they can't be passed easily to children processes.\n",
      "     |          shuffle: Boolean. Whether to shuffle the order of the batches at\n",
      "     |              the beginning of each epoch. Only used with instances\n",
      "     |              of `Sequence` (`keras.utils.Sequence`).\n",
      "     |              Has no effect when `steps_per_epoch` is not `None`.\n",
      "     |          initial_epoch: Epoch at which to start training\n",
      "     |              (useful for resuming a previous training run)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A `History` object.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          def generate_arrays_from_file(path):\n",
      "     |              while 1:\n",
      "     |                  f = open(path)\n",
      "     |                  for line in f:\n",
      "     |                      # create numpy arrays of input data\n",
      "     |                      # and labels, from each line in the file\n",
      "     |                      x1, x2, y = process_line(line)\n",
      "     |                      yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
      "     |                  f.close()\n",
      "     |      \n",
      "     |          model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      "     |                              steps_per_epoch=10000, epochs=10)\n",
      "     |      ```\n",
      "     |      Raises:\n",
      "     |          ValueError: In case the generator yields data in an invalid format.\n",
      "     |  \n",
      "     |  get_weights(self)\n",
      "     |      Retrieves the weights of the model.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A flat list of Numpy arrays.\n",
      "     |  \n",
      "     |  load_weights(self, filepath, by_name=False)\n",
      "     |      Loads all layer weights, either from a TensorFlow or an HDF5 file.\n",
      "     |  \n",
      "     |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      "     |      Generates output predictions for the input samples.\n",
      "     |      \n",
      "     |      Computation is done in batches.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input samples. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A `tf.data` dataset or a dataset iterator.\n",
      "     |            - A generator or `keras.utils.Sequence` instance.\n",
      "     |          batch_size: Integer or `None`.\n",
      "     |              Number of samples per gradient update.\n",
      "     |              If unspecified, `batch_size` will default to 32.\n",
      "     |              Do not specify the `batch_size` is your data is in the\n",
      "     |              form of symbolic tensors, dataset, dataset iterators,\n",
      "     |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      "     |              batches).\n",
      "     |          verbose: Verbosity mode, 0 or 1.\n",
      "     |          steps: Total number of steps (batches of samples)\n",
      "     |              before declaring the prediction round finished.\n",
      "     |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      "     |              dataset or a dataset iterator, and `steps` is None, `predict` will\n",
      "     |              run until the input dataset is exhausted.\n",
      "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      "     |              List of callbacks to apply during prediction.\n",
      "     |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "     |              input only. Maximum size for the generator queue.\n",
      "     |              If unspecified, `max_queue_size` will default to 10.\n",
      "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "     |              only. Maximum number of processes to spin up when using\n",
      "     |              process-based threading. If unspecified, `workers` will default\n",
      "     |              to 1. If 0, will execute the generator on the main thread.\n",
      "     |          use_multiprocessing: Boolean. Used for generator or\n",
      "     |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "     |              threading. If unspecified, `use_multiprocessing` will default to\n",
      "     |              `False`. Note that because this implementation relies on\n",
      "     |              multiprocessing, you should not pass non-picklable arguments to\n",
      "     |              the generator as they can't be passed easily to children processes.\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Numpy array(s) of predictions.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of mismatch between the provided\n",
      "     |              input data and the model's expectations,\n",
      "     |              or in case a stateful model receives a number of samples\n",
      "     |              that is not a multiple of the batch size.\n",
      "     |  \n",
      "     |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      "     |      Generates predictions for the input samples from a data generator.\n",
      "     |      \n",
      "     |      The generator should return the same kind of data as accepted by\n",
      "     |      `predict_on_batch`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          generator: Generator yielding batches of input samples\n",
      "     |              or an instance of `keras.utils.Sequence` object in order to\n",
      "     |              avoid duplicate data when using multiprocessing.\n",
      "     |          steps: Total number of steps (batches of samples)\n",
      "     |              to yield from `generator` before stopping.\n",
      "     |              Optional for `Sequence`: if unspecified, will use\n",
      "     |              the `len(generator)` as a number of steps.\n",
      "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      "     |              List of callbacks to apply during prediction.\n",
      "     |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      "     |          max_queue_size: Maximum size for the generator queue.\n",
      "     |          workers: Integer. Maximum number of processes to spin up\n",
      "     |              when using process-based threading.\n",
      "     |              If unspecified, `workers` will default to 1. If 0, will\n",
      "     |              execute the generator on the main thread.\n",
      "     |          use_multiprocessing: Boolean.\n",
      "     |              If `True`, use process-based threading.\n",
      "     |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      "     |              Note that because this implementation relies on multiprocessing,\n",
      "     |              you should not pass non-picklable arguments to the generator\n",
      "     |              as they can't be passed easily to children processes.\n",
      "     |          verbose: verbosity mode, 0 or 1.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Numpy array(s) of predictions.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case the generator yields data in an invalid format.\n",
      "     |  \n",
      "     |  predict_on_batch(self, x)\n",
      "     |      Returns predictions for a single batch of samples.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input data. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A `tf.data` dataset or a dataset iterator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Numpy array(s) of predictions.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of mismatch between given number of inputs and\n",
      "     |            expectations of the model.\n",
      "     |  \n",
      "     |  reset_metrics(self)\n",
      "     |      Resets the state of metrics.\n",
      "     |  \n",
      "     |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True)\n",
      "     |      Test the model on a single batch of samples.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input data. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A dict mapping input names to the corresponding array/tensors,\n",
      "     |              if the model has named inputs.\n",
      "     |            - A `tf.data` dataset or a dataset iterator.\n",
      "     |          y: Target data. Like the input data `x`,\n",
      "     |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "     |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "     |            tensor targets, or inversely). If `x` is a dataset or a\n",
      "     |            dataset iterator, `y` should not be specified\n",
      "     |            (since targets will be obtained from the iterator).\n",
      "     |          sample_weight: Optional array of the same length as x, containing\n",
      "     |              weights to apply to the model's loss for each sample.\n",
      "     |              In the case of temporal data, you can pass a 2D array\n",
      "     |              with shape (samples, sequence_length),\n",
      "     |              to apply a different weight to every timestep of every sample.\n",
      "     |              In this case you should make sure to specify\n",
      "     |              sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      "     |              supported when `x` is a dataset or a dataset iterator.\n",
      "     |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      "     |            batch. If `False`, the metrics will be statefully accumulated across\n",
      "     |            batches.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Scalar test loss (if the model has a single output and no metrics)\n",
      "     |          or list of scalars (if the model has multiple outputs\n",
      "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      "     |          the display labels for the scalar outputs.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of invalid user-provided arguments.\n",
      "     |  \n",
      "     |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True)\n",
      "     |      Runs a single gradient update on a single batch of data.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input data. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |                (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |                (in case the model has multiple inputs).\n",
      "     |            - A dict mapping input names to the corresponding array/tensors,\n",
      "     |                if the model has named inputs.\n",
      "     |            - A `tf.data` dataset or a dataset iterator.\n",
      "     |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      "     |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      "     |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      "     |            `x` is a dataset or a dataset iterator, `y` should not be specified\n",
      "     |            (since targets will be obtained from the iterator).\n",
      "     |          sample_weight: Optional array of the same length as x, containing\n",
      "     |            weights to apply to the model's loss for each sample. In the case of\n",
      "     |            temporal data, you can pass a 2D array with shape (samples,\n",
      "     |            sequence_length), to apply a different weight to every timestep of\n",
      "     |            every sample. In this case you should make sure to specify\n",
      "     |            sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      "     |            supported when `x` is a dataset or a dataset iterator.\n",
      "     |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      "     |            weight (float) to apply to the model's loss for the samples from this\n",
      "     |            class during training. This can be useful to tell the model to \"pay\n",
      "     |            more attention\" to samples from an under-represented class.\n",
      "     |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      "     |            batch. If `False`, the metrics will be statefully accumulated across\n",
      "     |            batches.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Scalar training loss\n",
      "     |          (if the model has a single output and no metrics)\n",
      "     |          or list of scalars (if the model has multiple outputs\n",
      "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      "     |          the display labels for the scalar outputs.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: In case of invalid user-provided arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  metrics\n",
      "     |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      "     |  \n",
      "     |  metrics_names\n",
      "     |      Returns the model's display labels for all outputs.\n",
      "     |  \n",
      "     |  run_eagerly\n",
      "     |      Settable attribute indicating whether the model should run eagerly.\n",
      "     |      \n",
      "     |      Running eagerly means that your model will be run step by step,\n",
      "     |      like Python code. Your model might run slower, but it should become easier\n",
      "     |      for you to debug it by stepping into individual layer calls.\n",
      "     |      \n",
      "     |      By default, we will attempt to compile your model to a static graph to\n",
      "     |      deliver the best execution performance.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Boolean, whether the model should run eagerly.\n",
      "     |  \n",
      "     |  sample_weights\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.keras.engine.network.Network:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  build(self, input_shape)\n",
      "     |      Builds the model based on input shapes received.\n",
      "     |      \n",
      "     |      This is to be used for subclassed models, which do not know at instantiation\n",
      "     |      time what their inputs look like.\n",
      "     |      \n",
      "     |      This method only exists for users who want to call `model.build()` in a\n",
      "     |      standalone way (as a substitute for calling the model on real data to\n",
      "     |      build it). It will never be called by the framework (and thus it will\n",
      "     |      never throw unexpected errors in an unrelated workflow).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
      "     |           are tuples, integers, or TensorShapes.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError:\n",
      "     |          1. In case of invalid user-provided data (not of type tuple,\n",
      "     |             list, or TensorShape).\n",
      "     |          2. If the model requires call arguments that are agnostic\n",
      "     |             to the input shapes (positional or kwarg in call signature).\n",
      "     |          3. If not all layers were properly built.\n",
      "     |          4. If float type inputs are not supported within the layers.\n",
      "     |      \n",
      "     |        In each of these cases, the user should build their model by calling it\n",
      "     |        on real tensor data.\n",
      "     |  \n",
      "     |  call(self, inputs, training=None, mask=None)\n",
      "     |      Calls the model on new inputs.\n",
      "     |      \n",
      "     |      In this case `call` just reapplies\n",
      "     |      all ops in the graph to the new inputs\n",
      "     |      (e.g. build a new computational graph from the provided inputs).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          inputs: A tensor or list of tensors.\n",
      "     |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      "     |            the `Network` in training mode or inference mode.\n",
      "     |          mask: A mask or list of masks. A mask can be\n",
      "     |              either a tensor or None (no mask).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A tensor if there is a single output, or\n",
      "     |          a list of tensors if there are more than one outputs.\n",
      "     |  \n",
      "     |  compute_mask(self, inputs, mask)\n",
      "     |      Computes an output mask tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          inputs: Tensor or list of tensors.\n",
      "     |          mask: Tensor or list of tensors.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          None or a tensor (or list of tensors,\n",
      "     |              one per output tensor of the layer).\n",
      "     |  \n",
      "     |  compute_output_shape(self, input_shape)\n",
      "     |      Computes the output shape of the layer.\n",
      "     |      \n",
      "     |      Assumes that the layer will be built\n",
      "     |      to match that input shape provided.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          input_shape: Shape tuple (tuple of integers)\n",
      "     |              or list of shape tuples (one per output tensor of the layer).\n",
      "     |              Shape tuples can include None for free dimensions,\n",
      "     |              instead of an integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          An input shape tuple.\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the config of the layer.\n",
      "     |      \n",
      "     |      A layer config is a Python dictionary (serializable)\n",
      "     |      containing the configuration of a layer.\n",
      "     |      The same layer can be reinstantiated later\n",
      "     |      (without its trained weights) from this configuration.\n",
      "     |      \n",
      "     |      The config of a layer does not include connectivity\n",
      "     |      information, nor the layer class name. These are handled\n",
      "     |      by `Network` (one layer of abstraction above).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Python dictionary.\n",
      "     |  \n",
      "     |  get_layer(self, name=None, index=None)\n",
      "     |      Retrieves a layer based on either its name (unique) or index.\n",
      "     |      \n",
      "     |      If `name` and `index` are both provided, `index` will take precedence.\n",
      "     |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          name: String, name of layer.\n",
      "     |          index: Integer, index of layer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A layer instance.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of invalid layer name or index.\n",
      "     |  \n",
      "     |  reset_states(self)\n",
      "     |  \n",
      "     |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None)\n",
      "     |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      "     |      \n",
      "     |      The savefile includes:\n",
      "     |          - The model architecture, allowing to re-instantiate the model.\n",
      "     |          - The model weights.\n",
      "     |          - The state of the optimizer, allowing to resume training\n",
      "     |              exactly where you left off.\n",
      "     |      \n",
      "     |      This allows you to save the entirety of the state of a model\n",
      "     |      in a single file.\n",
      "     |      \n",
      "     |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      "     |      The model returned by `load_model`\n",
      "     |      is a compiled model ready to be used (unless the saved model\n",
      "     |      was never compiled in the first place).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          filepath: String, path to SavedModel or H5 file to save the model.\n",
      "     |          overwrite: Whether to silently overwrite any existing file at the\n",
      "     |              target location, or provide the user with a manual prompt.\n",
      "     |          include_optimizer: If True, save optimizer's state together.\n",
      "     |          save_format: Either 'tf' or 'h5', indicating whether to save the model\n",
      "     |            to Tensorflow SavedModel or HDF5. The default is currently 'h5', but\n",
      "     |            will switch to 'tf' in TensorFlow 2.0. The 'tf' option is currently\n",
      "     |            disabled (use `tf.keras.experimental.export_saved_model` instead).\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      from keras.models import load_model\n",
      "     |      \n",
      "     |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      "     |      del model  # deletes the existing model\n",
      "     |      \n",
      "     |      # returns a compiled model\n",
      "     |      # identical to the previous one\n",
      "     |      model = load_model('my_model.h5')\n",
      "     |      ```\n",
      "     |  \n",
      "     |  save_weights(self, filepath, overwrite=True, save_format=None)\n",
      "     |      Saves all layer weights.\n",
      "     |      \n",
      "     |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      "     |      argument.\n",
      "     |      \n",
      "     |      When saving in HDF5 format, the weight file has:\n",
      "     |        - `layer_names` (attribute), a list of strings\n",
      "     |            (ordered names of model layers).\n",
      "     |        - For every layer, a `group` named `layer.name`\n",
      "     |            - For every such layer group, a group attribute `weight_names`,\n",
      "     |                a list of strings\n",
      "     |                (ordered names of weights tensor of the layer).\n",
      "     |            - For every weight in the layer, a dataset\n",
      "     |                storing the weight value, named after the weight tensor.\n",
      "     |      \n",
      "     |      When saving in TensorFlow format, all objects referenced by the network are\n",
      "     |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      "     |      instances or `Optimizer` instances assigned to object attributes. For\n",
      "     |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      "     |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      "     |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      "     |      `Layer` instances must be assigned to object attributes, typically in the\n",
      "     |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      "     |      `tf.keras.Model` for details.\n",
      "     |      \n",
      "     |      While the formats are the same, do not mix `save_weights` and\n",
      "     |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      "     |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      "     |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      "     |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      "     |      `save_weights` for training checkpoints.\n",
      "     |      \n",
      "     |      The TensorFlow format matches objects and variables by starting at a root\n",
      "     |      object, `self` for `save_weights`, and greedily matching attribute\n",
      "     |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      "     |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      "     |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      "     |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      "     |      the `Model`'s variables. See the [guide to training\n",
      "     |      checkpoints](https://www.tensorflow.org/alpha/guide/checkpoints) for details\n",
      "     |      on the TensorFlow format.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          filepath: String, path to the file to save the weights to. When saving\n",
      "     |              in TensorFlow format, this is the prefix used for checkpoint files\n",
      "     |              (multiple files are generated). Note that the '.h5' suffix causes\n",
      "     |              weights to be saved in HDF5 format.\n",
      "     |          overwrite: Whether to silently overwrite any existing file at the\n",
      "     |              target location, or provide the user with a manual prompt.\n",
      "     |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      "     |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      "     |              `None` defaults to 'tf'.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      "     |              format.\n",
      "     |          ValueError: For invalid/unknown format arguments.\n",
      "     |  \n",
      "     |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      "     |      Prints a string summary of the network.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          line_length: Total length of printed lines\n",
      "     |              (e.g. set this to adapt the display to different\n",
      "     |              terminal window sizes).\n",
      "     |          positions: Relative or absolute positions of log elements\n",
      "     |              in each line. If not provided,\n",
      "     |              defaults to `[.33, .55, .67, 1.]`.\n",
      "     |          print_fn: Print function to use. Defaults to `print`.\n",
      "     |              It will be called on each line of the summary.\n",
      "     |              You can set it to a custom function\n",
      "     |              in order to capture the string summary.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: if `summary()` is called before the model is built.\n",
      "     |  \n",
      "     |  to_json(self, **kwargs)\n",
      "     |      Returns a JSON string containing the network configuration.\n",
      "     |      \n",
      "     |      To load a network from a JSON save file, use\n",
      "     |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          **kwargs: Additional keyword arguments\n",
      "     |              to be passed to `json.dumps()`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A JSON string.\n",
      "     |  \n",
      "     |  to_yaml(self, **kwargs)\n",
      "     |      Returns a yaml string containing the network configuration.\n",
      "     |      \n",
      "     |      To load a network from a yaml save file, use\n",
      "     |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      "     |      \n",
      "     |      `custom_objects` should be a dictionary mapping\n",
      "     |      the names of custom losses / layers / etc to the corresponding\n",
      "     |      functions / classes.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          **kwargs: Additional keyword arguments\n",
      "     |              to be passed to `yaml.dump()`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A YAML string.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ImportError: if yaml module is not found.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.keras.engine.network.Network:\n",
      "     |  \n",
      "     |  from_config(config, custom_objects=None) from builtins.type\n",
      "     |      Instantiates a Model from its config (output of `get_config()`).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          config: Model config dictionary.\n",
      "     |          custom_objects: Optional dictionary mapping names\n",
      "     |              (strings) to custom classes or functions to be\n",
      "     |              considered during deserialization.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A model instance.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of improperly formatted config dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.keras.engine.network.Network:\n",
      "     |  \n",
      "     |  dynamic\n",
      "     |  \n",
      "     |  input_spec\n",
      "     |      Gets the network's input specs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A list of `InputSpec` instances (one per input to the model)\n",
      "     |              or a single instance if the model has only one input.\n",
      "     |  \n",
      "     |  layers\n",
      "     |  \n",
      "     |  non_trainable_weights\n",
      "     |  \n",
      "     |  state_updates\n",
      "     |      Returns the `updates` from all layers that are stateful.\n",
      "     |      \n",
      "     |      This is useful for separating training updates and\n",
      "     |      state updates, e.g. when we need to update a layer's internal state\n",
      "     |      during prediction.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A list of update ops.\n",
      "     |  \n",
      "     |  stateful\n",
      "     |  \n",
      "     |  trainable_weights\n",
      "     |  \n",
      "     |  weights\n",
      "     |      Returns the list of all layer variables/weights.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      "     |  \n",
      "     |  __call__(self, inputs, *args, **kwargs)\n",
      "     |      Wraps `call`, applying pre- and post-processing steps.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        inputs: input tensor(s).\n",
      "     |        *args: additional positional arguments to be passed to `self.call`.\n",
      "     |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Output tensor(s).\n",
      "     |      \n",
      "     |      Note:\n",
      "     |        - The following optional keyword arguments are reserved for specific uses:\n",
      "     |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      "     |            whether the `call` is meant for training or inference.\n",
      "     |          * `mask`: Boolean input mask.\n",
      "     |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      "     |          layers do), its default value will be set to the mask generated\n",
      "     |          for `inputs` by the previous layer (if `input` did come from\n",
      "     |          a layer that generated a corresponding mask, i.e. if it came from\n",
      "     |          a Keras layer with masking support.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  add_loss(self, losses, inputs=None)\n",
      "     |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      "     |      \n",
      "     |      Some losses (for instance, activity regularization losses) may be dependent\n",
      "     |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      "     |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      "     |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      "     |      of dependencies.\n",
      "     |      \n",
      "     |      This method can be used inside a subclassed layer or model's `call`\n",
      "     |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      class MyLayer(tf.keras.layers.Layer):\n",
      "     |        def call(inputs, self):\n",
      "     |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      "     |          return inputs\n",
      "     |      ```\n",
      "     |      \n",
      "     |      This method can also be called directly on a Functional Model during\n",
      "     |      construction. In this case, any loss Tensors passed to this Model must\n",
      "     |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      "     |      losses become part of the model's topology and are tracked in `get_config`.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      inputs = tf.keras.Input(shape=(10,))\n",
      "     |      x = tf.keras.layers.Dense(10)(inputs)\n",
      "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
      "     |      model = tf.keras.Model(inputs, outputs)\n",
      "     |      # Actvity regularization.\n",
      "     |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      If this is not the case for your loss (if, for example, your loss references\n",
      "     |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      "     |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      "     |      topology since they can't be serialized.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      inputs = tf.keras.Input(shape=(10,))\n",
      "     |      x = tf.keras.layers.Dense(10)(inputs)\n",
      "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
      "     |      model = tf.keras.Model(inputs, outputs)\n",
      "     |      # Weight regularization.\n",
      "     |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      "     |      specific set of inputs.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      "     |          may also be zero-argument callables which create a loss tensor.\n",
      "     |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      "     |          passed, it signals the losses are conditional on some of the layer's\n",
      "     |          inputs, and thus they should only be run where these inputs are\n",
      "     |          available. This is the case for activity regularization losses, for\n",
      "     |          instance. If `None` is passed, the losses are assumed\n",
      "     |          to be unconditional, and will apply across all dataflows of the layer\n",
      "     |          (e.g. weight regularization losses).\n",
      "     |  \n",
      "     |  add_metric(self, value, aggregation=None, name=None)\n",
      "     |      Adds metric tensor to the layer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: Metric tensor.\n",
      "     |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      "     |          it indicates that the metric tensor provided has been aggregated\n",
      "     |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      "     |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      "     |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      "     |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      "     |          aggregation='mean')`.\n",
      "     |        name: String metric name.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      "     |  \n",
      "     |  add_update(self, updates, inputs=None)\n",
      "     |      Add update op(s), potentially dependent on layer inputs.\n",
      "     |      \n",
      "     |      Weight updates (for instance, the updates of the moving mean and variance\n",
      "     |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      "     |      when calling a layer. Hence, when reusing the same layer on\n",
      "     |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      "     |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      "     |      of dependencies.\n",
      "     |      \n",
      "     |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      "     |      specific set of inputs.\n",
      "     |      \n",
      "     |      This call is ignored when eager execution is enabled (in that case, variable\n",
      "     |      updates are run on the fly and thus do not need to be tracked for later\n",
      "     |      execution).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      "     |          that returns an update op. A zero-arg callable should be passed in\n",
      "     |          order to disable running the updates by setting `trainable=False`\n",
      "     |          on this Layer, when executing in Eager mode.\n",
      "     |        inputs: If anything other than None is passed, it signals the updates\n",
      "     |          are conditional on some of the layer's inputs,\n",
      "     |          and thus they should only be run where these inputs are available.\n",
      "     |          This is the case for BatchNormalization updates, for instance.\n",
      "     |          If None, the updates will be taken into account unconditionally,\n",
      "     |          and you are responsible for making sure that any dependency they might\n",
      "     |          have is available at runtime.\n",
      "     |          A step counter might fall into this category.\n",
      "     |  \n",
      "     |  add_variable(self, *args, **kwargs)\n",
      "     |      Alias for `add_weight`.\n",
      "     |  \n",
      "     |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      "     |      Adds a new variable to the layer.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        name: Variable name.\n",
      "     |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      "     |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      "     |        initializer: initializer instance (callable).\n",
      "     |        regularizer: regularizer instance (callable).\n",
      "     |        trainable: whether the variable should be part of the layer's\n",
      "     |          \"trainable_variables\" (e.g. variables, biases)\n",
      "     |          or \"non_trainable_variables\" (e.g. BatchNorm mean, stddev).\n",
      "     |          Note, if the current variable scope is marked as non-trainable\n",
      "     |          then this parameter is ignored and any added variables are also\n",
      "     |          marked as non-trainable. `trainable` defaults to `True` unless\n",
      "     |          `synchronization` is set to `ON_READ`.\n",
      "     |        constraint: constraint instance (callable).\n",
      "     |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      "     |        use_resource: Whether to use `ResourceVariable`.\n",
      "     |        synchronization: Indicates when a distributed a variable will be\n",
      "     |          aggregated. Accepted values are constants defined in the class\n",
      "     |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "     |          `AUTO` and the current `DistributionStrategy` chooses\n",
      "     |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      "     |          `trainable` must not be set to `True`.\n",
      "     |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      "     |          Accepted values are constants defined in the class\n",
      "     |          `tf.VariableAggregation`.\n",
      "     |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      "     |          `collections`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created variable.  Usually either a `Variable` or `ResourceVariable`\n",
      "     |        instance.  If `partitioner` is not `None`, a `PartitionedVariable`\n",
      "     |        instance is returned.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called with partioned variable regularization and\n",
      "     |          eager execution is enabled.\n",
      "     |        ValueError: When giving unsupported dtype and no initializer or when\n",
      "     |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      "     |  \n",
      "     |  apply(self, inputs, *args, **kwargs)\n",
      "     |      Apply the layer on a input.\n",
      "     |      \n",
      "     |      This is an alias of `self.__call__`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        inputs: Input tensor(s).\n",
      "     |        *args: additional positional arguments to be passed to `self.call`.\n",
      "     |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Output tensor(s).\n",
      "     |  \n",
      "     |  count_params(self)\n",
      "     |      Count the total number of scalars composing the weights.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          An integer count.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: if the layer isn't yet built\n",
      "     |            (in which case its weights aren't yet defined).\n",
      "     |  \n",
      "     |  get_input_at(self, node_index)\n",
      "     |      Retrieves the input tensor(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called in Eager mode.\n",
      "     |  \n",
      "     |  get_input_mask_at(self, node_index)\n",
      "     |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A mask tensor\n",
      "     |          (or list of tensors if the layer has multiple inputs).\n",
      "     |  \n",
      "     |  get_input_shape_at(self, node_index)\n",
      "     |      Retrieves the input shape(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A shape tuple\n",
      "     |          (or list of shape tuples if the layer has multiple inputs).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called in Eager mode.\n",
      "     |  \n",
      "     |  get_losses_for(self, inputs)\n",
      "     |      Retrieves losses relevant to a specific set of inputs.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        inputs: Input tensor or list/tuple of input tensors.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        List of loss tensors of the layer that depend on `inputs`.\n",
      "     |  \n",
      "     |  get_output_at(self, node_index)\n",
      "     |      Retrieves the output tensor(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called in Eager mode.\n",
      "     |  \n",
      "     |  get_output_mask_at(self, node_index)\n",
      "     |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A mask tensor\n",
      "     |          (or list of tensors if the layer has multiple outputs).\n",
      "     |  \n",
      "     |  get_output_shape_at(self, node_index)\n",
      "     |      Retrieves the output shape(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A shape tuple\n",
      "     |          (or list of shape tuples if the layer has multiple outputs).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called in Eager mode.\n",
      "     |  \n",
      "     |  get_updates_for(self, inputs)\n",
      "     |      Retrieves updates relevant to a specific set of inputs.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        inputs: Input tensor or list/tuple of input tensors.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        List of update ops of the layer that depend on `inputs`.\n",
      "     |  \n",
      "     |  set_weights(self, weights)\n",
      "     |      Sets the weights of the layer, from Numpy arrays.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          weights: a list of Numpy arrays. The number\n",
      "     |              of arrays and their shape must match\n",
      "     |              number of the dimensions of the weights\n",
      "     |              of the layer (i.e. it should match the\n",
      "     |              output of `get_weights`).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: If the provided weights list does not match the\n",
      "     |              layer's specifications.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      "     |  \n",
      "     |  activity_regularizer\n",
      "     |      Optional regularizer function for the output of this layer.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  inbound_nodes\n",
      "     |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      "     |  \n",
      "     |  input\n",
      "     |      Retrieves the input tensor(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has exactly one input,\n",
      "     |      i.e. if it is connected to one incoming layer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Input tensor or list of input tensors.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AttributeError: if the layer is connected to\n",
      "     |          more than one incoming layers.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called in Eager mode.\n",
      "     |        AttributeError: If no inbound nodes are found.\n",
      "     |  \n",
      "     |  input_mask\n",
      "     |      Retrieves the input mask tensor(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has exactly one inbound node,\n",
      "     |      i.e. if it is connected to one incoming layer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Input mask tensor (potentially None) or list of input\n",
      "     |          mask tensors.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AttributeError: if the layer is connected to\n",
      "     |          more than one incoming layers.\n",
      "     |  \n",
      "     |  input_shape\n",
      "     |      Retrieves the input shape(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has exactly one input,\n",
      "     |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      "     |      have the same shape.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Input shape, as an integer shape tuple\n",
      "     |          (or list of shape tuples, one tuple per input tensor).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AttributeError: if the layer has no defined input_shape.\n",
      "     |          RuntimeError: if called in Eager mode.\n",
      "     |  \n",
      "     |  losses\n",
      "     |      Losses which are associated with this `Layer`.\n",
      "     |      \n",
      "     |      Variable regularization tensors are created when this property is accessed,\n",
      "     |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      "     |      propagate gradients back to the corresponding variables.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of tensors.\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  non_trainable_variables\n",
      "     |  \n",
      "     |  outbound_nodes\n",
      "     |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      "     |  \n",
      "     |  output\n",
      "     |      Retrieves the output tensor(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has exactly one output,\n",
      "     |      i.e. if it is connected to one incoming layer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Output tensor or list of output tensors.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        AttributeError: if the layer is connected to more than one incoming\n",
      "     |          layers.\n",
      "     |        RuntimeError: if called in Eager mode.\n",
      "     |  \n",
      "     |  output_mask\n",
      "     |      Retrieves the output mask tensor(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has exactly one inbound node,\n",
      "     |      i.e. if it is connected to one incoming layer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Output mask tensor (potentially None) or list of output\n",
      "     |          mask tensors.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AttributeError: if the layer is connected to\n",
      "     |          more than one incoming layers.\n",
      "     |  \n",
      "     |  output_shape\n",
      "     |      Retrieves the output shape(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has one output,\n",
      "     |      or if all outputs have the same shape.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Output shape, as an integer shape tuple\n",
      "     |          (or list of shape tuples, one tuple per output tensor).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AttributeError: if the layer has no defined output shape.\n",
      "     |          RuntimeError: if called in Eager mode.\n",
      "     |  \n",
      "     |  trainable\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of variables owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  updates\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Returns the list of all layer variables/weights.\n",
      "     |      \n",
      "     |      Alias of `self.weights`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  with_name_scope(method) from builtins.type\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      ```\n",
      "     |      class MyModule(tf.Module):\n",
      "     |        @tf.Module.with_name_scope\n",
      "     |        def __call__(self, x):\n",
      "     |          if not hasattr(self, 'w'):\n",
      "     |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      "     |          return tf.matmul(x, self.w)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      mod = MyModule()\n",
      "     |      mod(tf.ones([8, 32]))\n",
      "     |      # ==> <tf.Tensor: ...>\n",
      "     |      mod.w\n",
      "     |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      ```\n",
      "     |      a = tf.Module()\n",
      "     |      b = tf.Module()\n",
      "     |      c = tf.Module()\n",
      "     |      a.b = b\n",
      "     |      b.c = c\n",
      "     |      assert list(a.submodules) == [b, c]\n",
      "     |      assert list(b.submodules) == [c]\n",
      "     |      assert list(c.submodules) == []\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Sequential(tensorflow.python.keras.engine.training.Model)\n",
      "     |  Sequential(layers=None, name=None)\n",
      "     |  \n",
      "     |  Linear stack of layers.\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      layers: list of layers to add to the model.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Optionally, the first layer can receive an `input_shape` argument:\n",
      "     |  model = Sequential()\n",
      "     |  model.add(Dense(32, input_shape=(500,)))\n",
      "     |  # Afterwards, we do automatic shape inference:\n",
      "     |  model.add(Dense(32))\n",
      "     |  \n",
      "     |  # This is identical to the following:\n",
      "     |  model = Sequential()\n",
      "     |  model.add(Dense(32, input_dim=500))\n",
      "     |  \n",
      "     |  # And to the following:\n",
      "     |  model = Sequential()\n",
      "     |  model.add(Dense(32, batch_input_shape=(None, 500)))\n",
      "     |  \n",
      "     |  # Note that you can also omit the `input_shape` argument:\n",
      "     |  # In that case the model gets built the first time you call `fit` (or other\n",
      "     |  # training and evaluation methods).\n",
      "     |  model = Sequential()\n",
      "     |  model.add(Dense(32))\n",
      "     |  model.add(Dense(32))\n",
      "     |  model.compile(optimizer=optimizer, loss=loss)\n",
      "     |  # This builds the model for the first time:\n",
      "     |  model.fit(x, y, batch_size=32, epochs=10)\n",
      "     |  \n",
      "     |  # Note that when using this delayed-build pattern (no input shape specified),\n",
      "     |  # the model doesn't have any weights until the first call\n",
      "     |  # to a training/evaluation method (since it isn't yet built):\n",
      "     |  model = Sequential()\n",
      "     |  model.add(Dense(32))\n",
      "     |  model.add(Dense(32))\n",
      "     |  model.weights  # returns []\n",
      "     |  \n",
      "     |  # Whereas if you specify the input shape, the model gets built continuously\n",
      "     |  # as you are adding layers:\n",
      "     |  model = Sequential()\n",
      "     |  model.add(Dense(32, input_shape=(500,)))\n",
      "     |  model.add(Dense(32))\n",
      "     |  model.weights  # returns list of length 4\n",
      "     |  \n",
      "     |  # When using the delayed-build pattern (no input shape specified), you can\n",
      "     |  # choose to manually build your model by calling `build(batch_input_shape)`:\n",
      "     |  model = Sequential()\n",
      "     |  model.add(Dense(32))\n",
      "     |  model.add(Dense(32))\n",
      "     |  model.build((None, 500))\n",
      "     |  model.weights  # returns list of length 4\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Sequential\n",
      "     |      tensorflow.python.keras.engine.training.Model\n",
      "     |      tensorflow.python.keras.engine.network.Network\n",
      "     |      tensorflow.python.keras.engine.base_layer.Layer\n",
      "     |      tensorflow.python.module.module.Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, layers=None, name=None)\n",
      "     |  \n",
      "     |  add(self, layer)\n",
      "     |      Adds a layer instance on top of the layer stack.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          layer: layer instance.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          TypeError: If `layer` is not a layer instance.\n",
      "     |          ValueError: In case the `layer` argument does not\n",
      "     |              know its input shape.\n",
      "     |          ValueError: In case the `layer` argument has\n",
      "     |              multiple output tensors, or is already connected\n",
      "     |              somewhere else (forbidden in `Sequential` models).\n",
      "     |  \n",
      "     |  build(self, input_shape=None)\n",
      "     |      Builds the model based on input shapes received.\n",
      "     |      \n",
      "     |      This is to be used for subclassed models, which do not know at instantiation\n",
      "     |      time what their inputs look like.\n",
      "     |      \n",
      "     |      This method only exists for users who want to call `model.build()` in a\n",
      "     |      standalone way (as a substitute for calling the model on real data to\n",
      "     |      build it). It will never be called by the framework (and thus it will\n",
      "     |      never throw unexpected errors in an unrelated workflow).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
      "     |           are tuples, integers, or TensorShapes.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError:\n",
      "     |          1. In case of invalid user-provided data (not of type tuple,\n",
      "     |             list, or TensorShape).\n",
      "     |          2. If the model requires call arguments that are agnostic\n",
      "     |             to the input shapes (positional or kwarg in call signature).\n",
      "     |          3. If not all layers were properly built.\n",
      "     |          4. If float type inputs are not supported within the layers.\n",
      "     |      \n",
      "     |        In each of these cases, the user should build their model by calling it\n",
      "     |        on real tensor data.\n",
      "     |  \n",
      "     |  call(self, inputs, training=None, mask=None)\n",
      "     |      Calls the model on new inputs.\n",
      "     |      \n",
      "     |      In this case `call` just reapplies\n",
      "     |      all ops in the graph to the new inputs\n",
      "     |      (e.g. build a new computational graph from the provided inputs).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          inputs: A tensor or list of tensors.\n",
      "     |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      "     |            the `Network` in training mode or inference mode.\n",
      "     |          mask: A mask or list of masks. A mask can be\n",
      "     |              either a tensor or None (no mask).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A tensor if there is a single output, or\n",
      "     |          a list of tensors if there are more than one outputs.\n",
      "     |  \n",
      "     |  compute_mask(self, inputs, mask)\n",
      "     |      Computes an output mask tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          inputs: Tensor or list of tensors.\n",
      "     |          mask: Tensor or list of tensors.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          None or a tensor (or list of tensors,\n",
      "     |              one per output tensor of the layer).\n",
      "     |  \n",
      "     |  compute_output_shape(self, input_shape)\n",
      "     |      Computes the output shape of the layer.\n",
      "     |      \n",
      "     |      Assumes that the layer will be built\n",
      "     |      to match that input shape provided.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          input_shape: Shape tuple (tuple of integers)\n",
      "     |              or list of shape tuples (one per output tensor of the layer).\n",
      "     |              Shape tuples can include None for free dimensions,\n",
      "     |              instead of an integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          An input shape tuple.\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the config of the layer.\n",
      "     |      \n",
      "     |      A layer config is a Python dictionary (serializable)\n",
      "     |      containing the configuration of a layer.\n",
      "     |      The same layer can be reinstantiated later\n",
      "     |      (without its trained weights) from this configuration.\n",
      "     |      \n",
      "     |      The config of a layer does not include connectivity\n",
      "     |      information, nor the layer class name. These are handled\n",
      "     |      by `Network` (one layer of abstraction above).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Python dictionary.\n",
      "     |  \n",
      "     |  pop(self)\n",
      "     |      Removes the last layer in the model.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          TypeError: if there are no layers in the model.\n",
      "     |  \n",
      "     |  predict_classes(self, x, batch_size=32, verbose=0)\n",
      "     |      Generate class predictions for the input samples.\n",
      "     |      \n",
      "     |      The input samples are processed batch by batch.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: input data, as a Numpy array or list of Numpy arrays\n",
      "     |              (if the model has multiple inputs).\n",
      "     |          batch_size: integer.\n",
      "     |          verbose: verbosity mode, 0 or 1.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A numpy array of class predictions.\n",
      "     |  \n",
      "     |  predict_proba(self, x, batch_size=32, verbose=0)\n",
      "     |      Generates class probability predictions for the input samples.\n",
      "     |      \n",
      "     |      The input samples are processed batch by batch.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: input data, as a Numpy array or list of Numpy arrays\n",
      "     |              (if the model has multiple inputs).\n",
      "     |          batch_size: integer.\n",
      "     |          verbose: verbosity mode, 0 or 1.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A Numpy array of probability predictions.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_config(config, custom_objects=None) from builtins.type\n",
      "     |      Instantiates a Model from its config (output of `get_config()`).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          config: Model config dictionary.\n",
      "     |          custom_objects: Optional dictionary mapping names\n",
      "     |              (strings) to custom classes or functions to be\n",
      "     |              considered during deserialization.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A model instance.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of improperly formatted config dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  dynamic\n",
      "     |  \n",
      "     |  input_spec\n",
      "     |      Gets the network's input specs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A list of `InputSpec` instances (one per input to the model)\n",
      "     |              or a single instance if the model has only one input.\n",
      "     |  \n",
      "     |  layers\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      "     |  \n",
      "     |  compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, distribute=None, **kwargs)\n",
      "     |      Configures the model for training.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          optimizer: String (name of optimizer) or optimizer instance.\n",
      "     |              See `tf.keras.optimizers`.\n",
      "     |          loss: String (name of objective function), objective function or\n",
      "     |              `tf.losses.Loss` instance. See `tf.losses`. If the model has\n",
      "     |              multiple outputs, you can use a different loss on each output by\n",
      "     |              passing a dictionary or a list of losses. The loss value that will\n",
      "     |              be minimized by the model will then be the sum of all individual\n",
      "     |              losses.\n",
      "     |          metrics: List of metrics to be evaluated by the model during training\n",
      "     |              and testing. Typically you will use `metrics=['accuracy']`.\n",
      "     |              To specify different metrics for different outputs of a\n",
      "     |              multi-output model, you could also pass a dictionary, such as\n",
      "     |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      "     |              You can also pass a list (len = len(outputs)) of lists of metrics\n",
      "     |              such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      "     |              `metrics=['accuracy', ['accuracy', 'mse']]`.\n",
      "     |          loss_weights: Optional list or dictionary specifying scalar\n",
      "     |              coefficients (Python floats) to weight the loss contributions\n",
      "     |              of different model outputs.\n",
      "     |              The loss value that will be minimized by the model\n",
      "     |              will then be the *weighted sum* of all individual losses,\n",
      "     |              weighted by the `loss_weights` coefficients.\n",
      "     |              If a list, it is expected to have a 1:1 mapping\n",
      "     |              to the model's outputs. If a tensor, it is expected to map\n",
      "     |              output names (strings) to scalar coefficients.\n",
      "     |          sample_weight_mode: If you need to do timestep-wise\n",
      "     |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      "     |              `None` defaults to sample-wise weights (1D).\n",
      "     |              If the model has multiple outputs, you can use a different\n",
      "     |              `sample_weight_mode` on each output by passing a\n",
      "     |              dictionary or a list of modes.\n",
      "     |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      "     |              by sample_weight or class_weight during training and testing.\n",
      "     |          target_tensors: By default, Keras will create placeholders for the\n",
      "     |              model's target, which will be fed with the target data during\n",
      "     |              training. If instead you would like to use your own\n",
      "     |              target tensors (in turn, Keras will not expect external\n",
      "     |              Numpy data for these targets at training time), you\n",
      "     |              can specify them via the `target_tensors` argument. It can be\n",
      "     |              a single tensor (for a single-output model), a list of tensors,\n",
      "     |              or a dict mapping output names to target tensors.\n",
      "     |          distribute: NOT SUPPORTED IN TF 2.0, please create and compile the\n",
      "     |              model under distribution strategy scope instead of passing it to\n",
      "     |              compile.\n",
      "     |          **kwargs: Any additional arguments.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of invalid arguments for\n",
      "     |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      "     |  \n",
      "     |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      "     |      Returns the loss value & metrics values for the model in test mode.\n",
      "     |      \n",
      "     |      Computation is done in batches.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input data. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A dict mapping input names to the corresponding array/tensors,\n",
      "     |              if the model has named inputs.\n",
      "     |            - A `tf.data` dataset or a dataset iterator.\n",
      "     |            - A generator or `keras.utils.Sequence` instance.\n",
      "     |          y: Target data. Like the input data `x`,\n",
      "     |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "     |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "     |            tensor targets, or inversely).\n",
      "     |            If `x` is a dataset, dataset iterator, generator or\n",
      "     |            `keras.utils.Sequence` instance, `y` should not be specified (since\n",
      "     |            targets will be obtained from the iterator/dataset).\n",
      "     |          batch_size: Integer or `None`.\n",
      "     |              Number of samples per gradient update.\n",
      "     |              If unspecified, `batch_size` will default to 32.\n",
      "     |              Do not specify the `batch_size` is your data is in the\n",
      "     |              form of symbolic tensors, dataset, dataset iterators,\n",
      "     |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      "     |              batches).\n",
      "     |          verbose: 0 or 1. Verbosity mode.\n",
      "     |              0 = silent, 1 = progress bar.\n",
      "     |          sample_weight: Optional Numpy array of weights for\n",
      "     |              the test samples, used for weighting the loss function.\n",
      "     |              You can either pass a flat (1D)\n",
      "     |              Numpy array with the same length as the input samples\n",
      "     |              (1:1 mapping between weights and samples),\n",
      "     |              or in the case of temporal data,\n",
      "     |              you can pass a 2D array with shape\n",
      "     |              `(samples, sequence_length)`,\n",
      "     |              to apply a different weight to every timestep of every sample.\n",
      "     |              In this case you should make sure to specify\n",
      "     |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      "     |              supported when `x` is a dataset or a dataset iterator, instead pass\n",
      "     |              sample weights as the third element of `x`.\n",
      "     |          steps: Integer or `None`.\n",
      "     |              Total number of steps (batches of samples)\n",
      "     |              before declaring the evaluation round finished.\n",
      "     |              Ignored with the default value of `None`.\n",
      "     |              If x is a `tf.data` dataset or a dataset iterator, and `steps` is\n",
      "     |              None, 'evaluate' will run until the dataset is exhausted.\n",
      "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      "     |              List of callbacks to apply during evaluation.\n",
      "     |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "     |              input only. Maximum size for the generator queue.\n",
      "     |              If unspecified, `max_queue_size` will default to 10.\n",
      "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "     |              only. Maximum number of processes to spin up when using\n",
      "     |              process-based threading. If unspecified, `workers` will default\n",
      "     |              to 1. If 0, will execute the generator on the main thread.\n",
      "     |          use_multiprocessing: Boolean. Used for generator or\n",
      "     |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "     |              threading. If unspecified, `use_multiprocessing` will default to\n",
      "     |              `False`. Note that because this implementation relies on\n",
      "     |              multiprocessing, you should not pass non-picklable arguments to\n",
      "     |              the generator as they can't be passed easily to children processes.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Scalar test loss (if the model has a single output and no metrics)\n",
      "     |          or list of scalars (if the model has multiple outputs\n",
      "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      "     |          the display labels for the scalar outputs.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: in case of invalid arguments.\n",
      "     |  \n",
      "     |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      "     |      Evaluates the model on a data generator.\n",
      "     |      \n",
      "     |      The generator should return the same kind of data\n",
      "     |      as accepted by `test_on_batch`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          generator: Generator yielding tuples (inputs, targets)\n",
      "     |              or (inputs, targets, sample_weights)\n",
      "     |              or an instance of `keras.utils.Sequence`\n",
      "     |              object in order to avoid duplicate data\n",
      "     |              when using multiprocessing.\n",
      "     |          steps: Total number of steps (batches of samples)\n",
      "     |              to yield from `generator` before stopping.\n",
      "     |              Optional for `Sequence`: if unspecified, will use\n",
      "     |              the `len(generator)` as a number of steps.\n",
      "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      "     |              List of callbacks to apply during evaluation.\n",
      "     |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      "     |          max_queue_size: maximum size for the generator queue\n",
      "     |          workers: Integer. Maximum number of processes to spin up\n",
      "     |              when using process-based threading.\n",
      "     |              If unspecified, `workers` will default to 1. If 0, will\n",
      "     |              execute the generator on the main thread.\n",
      "     |          use_multiprocessing: Boolean.\n",
      "     |              If `True`, use process-based threading.\n",
      "     |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      "     |              Note that because this implementation relies on multiprocessing,\n",
      "     |              you should not pass non-picklable arguments to the generator\n",
      "     |              as they can't be passed easily to children processes.\n",
      "     |          verbose: Verbosity mode, 0 or 1.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Scalar test loss (if the model has a single output and no metrics)\n",
      "     |          or list of scalars (if the model has multiple outputs\n",
      "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      "     |          the display labels for the scalar outputs.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: in case of invalid arguments.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case the generator yields data in an invalid format.\n",
      "     |  \n",
      "     |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs)\n",
      "     |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input data. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A dict mapping input names to the corresponding array/tensors,\n",
      "     |              if the model has named inputs.\n",
      "     |            - A `tf.data` dataset or a dataset iterator. Should return a tuple\n",
      "     |              of either `(inputs, targets)` or\n",
      "     |              `(inputs, targets, sample_weights)`.\n",
      "     |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      "     |              or `(inputs, targets, sample weights)`.\n",
      "     |          y: Target data. Like the input data `x`,\n",
      "     |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "     |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "     |            tensor targets, or inversely). If `x` is a dataset, dataset\n",
      "     |            iterator, generator, or `keras.utils.Sequence` instance, `y` should\n",
      "     |            not be specified (since targets will be obtained from `x`).\n",
      "     |          batch_size: Integer or `None`.\n",
      "     |              Number of samples per gradient update.\n",
      "     |              If unspecified, `batch_size` will default to 32.\n",
      "     |              Do not specify the `batch_size` if your data is in the\n",
      "     |              form of symbolic tensors, dataset, dataset iterators,\n",
      "     |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      "     |              batches).\n",
      "     |          epochs: Integer. Number of epochs to train the model.\n",
      "     |              An epoch is an iteration over the entire `x` and `y`\n",
      "     |              data provided.\n",
      "     |              Note that in conjunction with `initial_epoch`,\n",
      "     |              `epochs` is to be understood as \"final epoch\".\n",
      "     |              The model is not trained for a number of iterations\n",
      "     |              given by `epochs`, but merely until the epoch\n",
      "     |              of index `epochs` is reached.\n",
      "     |          verbose: 0, 1, or 2. Verbosity mode.\n",
      "     |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "     |              Note that the progress bar is not particularly useful when\n",
      "     |              logged to a file, so verbose=2 is recommended when not running\n",
      "     |              interactively (eg, in a production environment).\n",
      "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      "     |              List of callbacks to apply during training.\n",
      "     |              See `tf.keras.callbacks`.\n",
      "     |          validation_split: Float between 0 and 1.\n",
      "     |              Fraction of the training data to be used as validation data.\n",
      "     |              The model will set apart this fraction of the training data,\n",
      "     |              will not train on it, and will evaluate\n",
      "     |              the loss and any model metrics\n",
      "     |              on this data at the end of each epoch.\n",
      "     |              The validation data is selected from the last samples\n",
      "     |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      "     |              not supported when `x` is a dataset, dataset iterator, generator or\n",
      "     |             `keras.utils.Sequence` instance.\n",
      "     |          validation_data: Data on which to evaluate\n",
      "     |              the loss and any model metrics at the end of each epoch.\n",
      "     |              The model will not be trained on this data.\n",
      "     |              `validation_data` will override `validation_split`.\n",
      "     |              `validation_data` could be:\n",
      "     |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      "     |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      "     |                - dataset or a dataset iterator\n",
      "     |              For the first two cases, `batch_size` must be provided.\n",
      "     |              For the last case, `validation_steps` must be provided.\n",
      "     |          shuffle: Boolean (whether to shuffle the training data\n",
      "     |              before each epoch) or str (for 'batch').\n",
      "     |              'batch' is a special option for dealing with the\n",
      "     |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      "     |              Has no effect when `steps_per_epoch` is not `None`.\n",
      "     |          class_weight: Optional dictionary mapping class indices (integers)\n",
      "     |              to a weight (float) value, used for weighting the loss function\n",
      "     |              (during training only).\n",
      "     |              This can be useful to tell the model to\n",
      "     |              \"pay more attention\" to samples from\n",
      "     |              an under-represented class.\n",
      "     |          sample_weight: Optional Numpy array of weights for\n",
      "     |              the training samples, used for weighting the loss function\n",
      "     |              (during training only). You can either pass a flat (1D)\n",
      "     |              Numpy array with the same length as the input samples\n",
      "     |              (1:1 mapping between weights and samples),\n",
      "     |              or in the case of temporal data,\n",
      "     |              you can pass a 2D array with shape\n",
      "     |              `(samples, sequence_length)`,\n",
      "     |              to apply a different weight to every timestep of every sample.\n",
      "     |              In this case you should make sure to specify\n",
      "     |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      "     |              supported when `x` is a dataset, dataset iterator, generator, or\n",
      "     |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      "     |              as the third element of `x`.\n",
      "     |          initial_epoch: Integer.\n",
      "     |              Epoch at which to start training\n",
      "     |              (useful for resuming a previous training run).\n",
      "     |          steps_per_epoch: Integer or `None`.\n",
      "     |              Total number of steps (batches of samples)\n",
      "     |              before declaring one epoch finished and starting the\n",
      "     |              next epoch. When training with input tensors such as\n",
      "     |              TensorFlow data tensors, the default `None` is equal to\n",
      "     |              the number of samples in your dataset divided by\n",
      "     |              the batch size, or 1 if that cannot be determined. If x is a\n",
      "     |              `tf.data` dataset or a dataset iterator, and 'steps_per_epoch'\n",
      "     |              is None, the epoch will run until the input dataset is exhausted.\n",
      "     |          validation_steps: Only relevant if `validation_data` is provided and\n",
      "     |              is a dataset or dataset iterator. Total number of steps (batches of\n",
      "     |              samples) to draw before stopping when performing validation\n",
      "     |              at the end of every epoch. If validation_data is a `tf.data` dataset\n",
      "     |              or a dataset iterator, and 'validation_steps' is None, validation\n",
      "     |              will run until the `validation_data` dataset is exhausted.\n",
      "     |          validation_freq: Only relevant if validation data is provided. Integer\n",
      "     |              or `collections.Container` instance (e.g. list, tuple, etc.). If an\n",
      "     |              integer, specifies how many training epochs to run before a new\n",
      "     |              validation run is performed, e.g. `validation_freq=2` runs\n",
      "     |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      "     |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      "     |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "     |              input only. Maximum size for the generator queue.\n",
      "     |              If unspecified, `max_queue_size` will default to 10.\n",
      "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "     |              only. Maximum number of processes to spin up\n",
      "     |              when using process-based threading. If unspecified, `workers`\n",
      "     |              will default to 1. If 0, will execute the generator on the main\n",
      "     |              thread.\n",
      "     |          use_multiprocessing: Boolean. Used for generator or\n",
      "     |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "     |              threading. If unspecified, `use_multiprocessing` will default to\n",
      "     |              `False`. Note that because this implementation relies on\n",
      "     |              multiprocessing, you should not pass non-picklable arguments to\n",
      "     |              the generator as they can't be passed easily to children processes.\n",
      "     |          **kwargs: Used for backwards compatibility.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A `History` object. Its `History.history` attribute is\n",
      "     |          a record of training loss values and metrics values\n",
      "     |          at successive epochs, as well as validation loss values\n",
      "     |          and validation metrics values (if applicable).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          RuntimeError: If the model was never compiled.\n",
      "     |          ValueError: In case of mismatch between the provided input data\n",
      "     |              and what the model expects.\n",
      "     |  \n",
      "     |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      "     |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      "     |      \n",
      "     |      The generator is run in parallel to the model, for efficiency.\n",
      "     |      For instance, this allows you to do real-time data augmentation\n",
      "     |      on images on CPU in parallel to training your model on GPU.\n",
      "     |      \n",
      "     |      The use of `keras.utils.Sequence` guarantees the ordering\n",
      "     |      and guarantees the single use of every input per epoch when\n",
      "     |      using `use_multiprocessing=True`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          generator: A generator or an instance of `Sequence`\n",
      "     |            (`keras.utils.Sequence`)\n",
      "     |              object in order to avoid duplicate data\n",
      "     |              when using multiprocessing.\n",
      "     |              The output of the generator must be either\n",
      "     |              - a tuple `(inputs, targets)`\n",
      "     |              - a tuple `(inputs, targets, sample_weights)`.\n",
      "     |              This tuple (a single output of the generator) makes a single batch.\n",
      "     |              Therefore, all arrays in this tuple must have the same length (equal\n",
      "     |              to the size of this batch). Different batches may have different\n",
      "     |                sizes.\n",
      "     |              For example, the last batch of the epoch is commonly smaller than\n",
      "     |                the\n",
      "     |              others, if the size of the dataset is not divisible by the batch\n",
      "     |                size.\n",
      "     |              The generator is expected to loop over its data\n",
      "     |              indefinitely. An epoch finishes when `steps_per_epoch`\n",
      "     |              batches have been seen by the model.\n",
      "     |          steps_per_epoch: Total number of steps (batches of samples)\n",
      "     |              to yield from `generator` before declaring one epoch\n",
      "     |              finished and starting the next epoch. It should typically\n",
      "     |              be equal to the number of samples of your dataset\n",
      "     |              divided by the batch size.\n",
      "     |              Optional for `Sequence`: if unspecified, will use\n",
      "     |              the `len(generator)` as a number of steps.\n",
      "     |          epochs: Integer, total number of iterations on the data.\n",
      "     |          verbose: Verbosity mode, 0, 1, or 2.\n",
      "     |          callbacks: List of callbacks to be called during training.\n",
      "     |          validation_data: This can be either\n",
      "     |              - a generator for the validation data\n",
      "     |              - a tuple (inputs, targets)\n",
      "     |              - a tuple (inputs, targets, sample_weights).\n",
      "     |          validation_steps: Only relevant if `validation_data`\n",
      "     |              is a generator. Total number of steps (batches of samples)\n",
      "     |              to yield from `generator` before stopping.\n",
      "     |              Optional for `Sequence`: if unspecified, will use\n",
      "     |              the `len(validation_data)` as a number of steps.\n",
      "     |          validation_freq: Only relevant if validation data is provided. Integer\n",
      "     |              or `collections.Container` instance (e.g. list, tuple, etc.). If an\n",
      "     |              integer, specifies how many training epochs to run before a new\n",
      "     |              validation run is performed, e.g. `validation_freq=2` runs\n",
      "     |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      "     |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      "     |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      "     |          class_weight: Dictionary mapping class indices to a weight\n",
      "     |              for the class.\n",
      "     |          max_queue_size: Integer. Maximum size for the generator queue.\n",
      "     |              If unspecified, `max_queue_size` will default to 10.\n",
      "     |          workers: Integer. Maximum number of processes to spin up\n",
      "     |              when using process-based threading.\n",
      "     |              If unspecified, `workers` will default to 1. If 0, will\n",
      "     |              execute the generator on the main thread.\n",
      "     |          use_multiprocessing: Boolean.\n",
      "     |              If `True`, use process-based threading.\n",
      "     |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      "     |              Note that because this implementation relies on multiprocessing,\n",
      "     |              you should not pass non-picklable arguments to the generator\n",
      "     |              as they can't be passed easily to children processes.\n",
      "     |          shuffle: Boolean. Whether to shuffle the order of the batches at\n",
      "     |              the beginning of each epoch. Only used with instances\n",
      "     |              of `Sequence` (`keras.utils.Sequence`).\n",
      "     |              Has no effect when `steps_per_epoch` is not `None`.\n",
      "     |          initial_epoch: Epoch at which to start training\n",
      "     |              (useful for resuming a previous training run)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A `History` object.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          def generate_arrays_from_file(path):\n",
      "     |              while 1:\n",
      "     |                  f = open(path)\n",
      "     |                  for line in f:\n",
      "     |                      # create numpy arrays of input data\n",
      "     |                      # and labels, from each line in the file\n",
      "     |                      x1, x2, y = process_line(line)\n",
      "     |                      yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
      "     |                  f.close()\n",
      "     |      \n",
      "     |          model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      "     |                              steps_per_epoch=10000, epochs=10)\n",
      "     |      ```\n",
      "     |      Raises:\n",
      "     |          ValueError: In case the generator yields data in an invalid format.\n",
      "     |  \n",
      "     |  get_weights(self)\n",
      "     |      Retrieves the weights of the model.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A flat list of Numpy arrays.\n",
      "     |  \n",
      "     |  load_weights(self, filepath, by_name=False)\n",
      "     |      Loads all layer weights, either from a TensorFlow or an HDF5 file.\n",
      "     |  \n",
      "     |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      "     |      Generates output predictions for the input samples.\n",
      "     |      \n",
      "     |      Computation is done in batches.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input samples. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A `tf.data` dataset or a dataset iterator.\n",
      "     |            - A generator or `keras.utils.Sequence` instance.\n",
      "     |          batch_size: Integer or `None`.\n",
      "     |              Number of samples per gradient update.\n",
      "     |              If unspecified, `batch_size` will default to 32.\n",
      "     |              Do not specify the `batch_size` is your data is in the\n",
      "     |              form of symbolic tensors, dataset, dataset iterators,\n",
      "     |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      "     |              batches).\n",
      "     |          verbose: Verbosity mode, 0 or 1.\n",
      "     |          steps: Total number of steps (batches of samples)\n",
      "     |              before declaring the prediction round finished.\n",
      "     |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      "     |              dataset or a dataset iterator, and `steps` is None, `predict` will\n",
      "     |              run until the input dataset is exhausted.\n",
      "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      "     |              List of callbacks to apply during prediction.\n",
      "     |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      "     |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "     |              input only. Maximum size for the generator queue.\n",
      "     |              If unspecified, `max_queue_size` will default to 10.\n",
      "     |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "     |              only. Maximum number of processes to spin up when using\n",
      "     |              process-based threading. If unspecified, `workers` will default\n",
      "     |              to 1. If 0, will execute the generator on the main thread.\n",
      "     |          use_multiprocessing: Boolean. Used for generator or\n",
      "     |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "     |              threading. If unspecified, `use_multiprocessing` will default to\n",
      "     |              `False`. Note that because this implementation relies on\n",
      "     |              multiprocessing, you should not pass non-picklable arguments to\n",
      "     |              the generator as they can't be passed easily to children processes.\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Numpy array(s) of predictions.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of mismatch between the provided\n",
      "     |              input data and the model's expectations,\n",
      "     |              or in case a stateful model receives a number of samples\n",
      "     |              that is not a multiple of the batch size.\n",
      "     |  \n",
      "     |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      "     |      Generates predictions for the input samples from a data generator.\n",
      "     |      \n",
      "     |      The generator should return the same kind of data as accepted by\n",
      "     |      `predict_on_batch`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          generator: Generator yielding batches of input samples\n",
      "     |              or an instance of `keras.utils.Sequence` object in order to\n",
      "     |              avoid duplicate data when using multiprocessing.\n",
      "     |          steps: Total number of steps (batches of samples)\n",
      "     |              to yield from `generator` before stopping.\n",
      "     |              Optional for `Sequence`: if unspecified, will use\n",
      "     |              the `len(generator)` as a number of steps.\n",
      "     |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      "     |              List of callbacks to apply during prediction.\n",
      "     |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      "     |          max_queue_size: Maximum size for the generator queue.\n",
      "     |          workers: Integer. Maximum number of processes to spin up\n",
      "     |              when using process-based threading.\n",
      "     |              If unspecified, `workers` will default to 1. If 0, will\n",
      "     |              execute the generator on the main thread.\n",
      "     |          use_multiprocessing: Boolean.\n",
      "     |              If `True`, use process-based threading.\n",
      "     |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      "     |              Note that because this implementation relies on multiprocessing,\n",
      "     |              you should not pass non-picklable arguments to the generator\n",
      "     |              as they can't be passed easily to children processes.\n",
      "     |          verbose: verbosity mode, 0 or 1.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Numpy array(s) of predictions.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case the generator yields data in an invalid format.\n",
      "     |  \n",
      "     |  predict_on_batch(self, x)\n",
      "     |      Returns predictions for a single batch of samples.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input data. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A `tf.data` dataset or a dataset iterator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Numpy array(s) of predictions.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of mismatch between given number of inputs and\n",
      "     |            expectations of the model.\n",
      "     |  \n",
      "     |  reset_metrics(self)\n",
      "     |      Resets the state of metrics.\n",
      "     |  \n",
      "     |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True)\n",
      "     |      Test the model on a single batch of samples.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input data. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |              (in case the model has multiple inputs).\n",
      "     |            - A dict mapping input names to the corresponding array/tensors,\n",
      "     |              if the model has named inputs.\n",
      "     |            - A `tf.data` dataset or a dataset iterator.\n",
      "     |          y: Target data. Like the input data `x`,\n",
      "     |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "     |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "     |            tensor targets, or inversely). If `x` is a dataset or a\n",
      "     |            dataset iterator, `y` should not be specified\n",
      "     |            (since targets will be obtained from the iterator).\n",
      "     |          sample_weight: Optional array of the same length as x, containing\n",
      "     |              weights to apply to the model's loss for each sample.\n",
      "     |              In the case of temporal data, you can pass a 2D array\n",
      "     |              with shape (samples, sequence_length),\n",
      "     |              to apply a different weight to every timestep of every sample.\n",
      "     |              In this case you should make sure to specify\n",
      "     |              sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      "     |              supported when `x` is a dataset or a dataset iterator.\n",
      "     |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      "     |            batch. If `False`, the metrics will be statefully accumulated across\n",
      "     |            batches.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Scalar test loss (if the model has a single output and no metrics)\n",
      "     |          or list of scalars (if the model has multiple outputs\n",
      "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      "     |          the display labels for the scalar outputs.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of invalid user-provided arguments.\n",
      "     |  \n",
      "     |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True)\n",
      "     |      Runs a single gradient update on a single batch of data.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          x: Input data. It could be:\n",
      "     |            - A Numpy array (or array-like), or a list of arrays\n",
      "     |                (in case the model has multiple inputs).\n",
      "     |            - A TensorFlow tensor, or a list of tensors\n",
      "     |                (in case the model has multiple inputs).\n",
      "     |            - A dict mapping input names to the corresponding array/tensors,\n",
      "     |                if the model has named inputs.\n",
      "     |            - A `tf.data` dataset or a dataset iterator.\n",
      "     |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      "     |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      "     |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      "     |            `x` is a dataset or a dataset iterator, `y` should not be specified\n",
      "     |            (since targets will be obtained from the iterator).\n",
      "     |          sample_weight: Optional array of the same length as x, containing\n",
      "     |            weights to apply to the model's loss for each sample. In the case of\n",
      "     |            temporal data, you can pass a 2D array with shape (samples,\n",
      "     |            sequence_length), to apply a different weight to every timestep of\n",
      "     |            every sample. In this case you should make sure to specify\n",
      "     |            sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      "     |            supported when `x` is a dataset or a dataset iterator.\n",
      "     |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      "     |            weight (float) to apply to the model's loss for the samples from this\n",
      "     |            class during training. This can be useful to tell the model to \"pay\n",
      "     |            more attention\" to samples from an under-represented class.\n",
      "     |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      "     |            batch. If `False`, the metrics will be statefully accumulated across\n",
      "     |            batches.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Scalar training loss\n",
      "     |          (if the model has a single output and no metrics)\n",
      "     |          or list of scalars (if the model has multiple outputs\n",
      "     |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      "     |          the display labels for the scalar outputs.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: In case of invalid user-provided arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      "     |  \n",
      "     |  metrics\n",
      "     |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      "     |  \n",
      "     |  metrics_names\n",
      "     |      Returns the model's display labels for all outputs.\n",
      "     |  \n",
      "     |  run_eagerly\n",
      "     |      Settable attribute indicating whether the model should run eagerly.\n",
      "     |      \n",
      "     |      Running eagerly means that your model will be run step by step,\n",
      "     |      like Python code. Your model might run slower, but it should become easier\n",
      "     |      for you to debug it by stepping into individual layer calls.\n",
      "     |      \n",
      "     |      By default, we will attempt to compile your model to a static graph to\n",
      "     |      deliver the best execution performance.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Boolean, whether the model should run eagerly.\n",
      "     |  \n",
      "     |  sample_weights\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.keras.engine.network.Network:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  get_layer(self, name=None, index=None)\n",
      "     |      Retrieves a layer based on either its name (unique) or index.\n",
      "     |      \n",
      "     |      If `name` and `index` are both provided, `index` will take precedence.\n",
      "     |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          name: String, name of layer.\n",
      "     |          index: Integer, index of layer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A layer instance.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case of invalid layer name or index.\n",
      "     |  \n",
      "     |  reset_states(self)\n",
      "     |  \n",
      "     |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None)\n",
      "     |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      "     |      \n",
      "     |      The savefile includes:\n",
      "     |          - The model architecture, allowing to re-instantiate the model.\n",
      "     |          - The model weights.\n",
      "     |          - The state of the optimizer, allowing to resume training\n",
      "     |              exactly where you left off.\n",
      "     |      \n",
      "     |      This allows you to save the entirety of the state of a model\n",
      "     |      in a single file.\n",
      "     |      \n",
      "     |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      "     |      The model returned by `load_model`\n",
      "     |      is a compiled model ready to be used (unless the saved model\n",
      "     |      was never compiled in the first place).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          filepath: String, path to SavedModel or H5 file to save the model.\n",
      "     |          overwrite: Whether to silently overwrite any existing file at the\n",
      "     |              target location, or provide the user with a manual prompt.\n",
      "     |          include_optimizer: If True, save optimizer's state together.\n",
      "     |          save_format: Either 'tf' or 'h5', indicating whether to save the model\n",
      "     |            to Tensorflow SavedModel or HDF5. The default is currently 'h5', but\n",
      "     |            will switch to 'tf' in TensorFlow 2.0. The 'tf' option is currently\n",
      "     |            disabled (use `tf.keras.experimental.export_saved_model` instead).\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      from keras.models import load_model\n",
      "     |      \n",
      "     |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      "     |      del model  # deletes the existing model\n",
      "     |      \n",
      "     |      # returns a compiled model\n",
      "     |      # identical to the previous one\n",
      "     |      model = load_model('my_model.h5')\n",
      "     |      ```\n",
      "     |  \n",
      "     |  save_weights(self, filepath, overwrite=True, save_format=None)\n",
      "     |      Saves all layer weights.\n",
      "     |      \n",
      "     |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      "     |      argument.\n",
      "     |      \n",
      "     |      When saving in HDF5 format, the weight file has:\n",
      "     |        - `layer_names` (attribute), a list of strings\n",
      "     |            (ordered names of model layers).\n",
      "     |        - For every layer, a `group` named `layer.name`\n",
      "     |            - For every such layer group, a group attribute `weight_names`,\n",
      "     |                a list of strings\n",
      "     |                (ordered names of weights tensor of the layer).\n",
      "     |            - For every weight in the layer, a dataset\n",
      "     |                storing the weight value, named after the weight tensor.\n",
      "     |      \n",
      "     |      When saving in TensorFlow format, all objects referenced by the network are\n",
      "     |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      "     |      instances or `Optimizer` instances assigned to object attributes. For\n",
      "     |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      "     |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      "     |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      "     |      `Layer` instances must be assigned to object attributes, typically in the\n",
      "     |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      "     |      `tf.keras.Model` for details.\n",
      "     |      \n",
      "     |      While the formats are the same, do not mix `save_weights` and\n",
      "     |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      "     |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      "     |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      "     |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      "     |      `save_weights` for training checkpoints.\n",
      "     |      \n",
      "     |      The TensorFlow format matches objects and variables by starting at a root\n",
      "     |      object, `self` for `save_weights`, and greedily matching attribute\n",
      "     |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      "     |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      "     |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      "     |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      "     |      the `Model`'s variables. See the [guide to training\n",
      "     |      checkpoints](https://www.tensorflow.org/alpha/guide/checkpoints) for details\n",
      "     |      on the TensorFlow format.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          filepath: String, path to the file to save the weights to. When saving\n",
      "     |              in TensorFlow format, this is the prefix used for checkpoint files\n",
      "     |              (multiple files are generated). Note that the '.h5' suffix causes\n",
      "     |              weights to be saved in HDF5 format.\n",
      "     |          overwrite: Whether to silently overwrite any existing file at the\n",
      "     |              target location, or provide the user with a manual prompt.\n",
      "     |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      "     |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      "     |              `None` defaults to 'tf'.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      "     |              format.\n",
      "     |          ValueError: For invalid/unknown format arguments.\n",
      "     |  \n",
      "     |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      "     |      Prints a string summary of the network.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          line_length: Total length of printed lines\n",
      "     |              (e.g. set this to adapt the display to different\n",
      "     |              terminal window sizes).\n",
      "     |          positions: Relative or absolute positions of log elements\n",
      "     |              in each line. If not provided,\n",
      "     |              defaults to `[.33, .55, .67, 1.]`.\n",
      "     |          print_fn: Print function to use. Defaults to `print`.\n",
      "     |              It will be called on each line of the summary.\n",
      "     |              You can set it to a custom function\n",
      "     |              in order to capture the string summary.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: if `summary()` is called before the model is built.\n",
      "     |  \n",
      "     |  to_json(self, **kwargs)\n",
      "     |      Returns a JSON string containing the network configuration.\n",
      "     |      \n",
      "     |      To load a network from a JSON save file, use\n",
      "     |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          **kwargs: Additional keyword arguments\n",
      "     |              to be passed to `json.dumps()`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A JSON string.\n",
      "     |  \n",
      "     |  to_yaml(self, **kwargs)\n",
      "     |      Returns a yaml string containing the network configuration.\n",
      "     |      \n",
      "     |      To load a network from a yaml save file, use\n",
      "     |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      "     |      \n",
      "     |      `custom_objects` should be a dictionary mapping\n",
      "     |      the names of custom losses / layers / etc to the corresponding\n",
      "     |      functions / classes.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          **kwargs: Additional keyword arguments\n",
      "     |              to be passed to `yaml.dump()`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A YAML string.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ImportError: if yaml module is not found.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.keras.engine.network.Network:\n",
      "     |  \n",
      "     |  non_trainable_weights\n",
      "     |  \n",
      "     |  state_updates\n",
      "     |      Returns the `updates` from all layers that are stateful.\n",
      "     |      \n",
      "     |      This is useful for separating training updates and\n",
      "     |      state updates, e.g. when we need to update a layer's internal state\n",
      "     |      during prediction.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A list of update ops.\n",
      "     |  \n",
      "     |  stateful\n",
      "     |  \n",
      "     |  trainable_weights\n",
      "     |  \n",
      "     |  weights\n",
      "     |      Returns the list of all layer variables/weights.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      "     |  \n",
      "     |  __call__(self, inputs, *args, **kwargs)\n",
      "     |      Wraps `call`, applying pre- and post-processing steps.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        inputs: input tensor(s).\n",
      "     |        *args: additional positional arguments to be passed to `self.call`.\n",
      "     |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Output tensor(s).\n",
      "     |      \n",
      "     |      Note:\n",
      "     |        - The following optional keyword arguments are reserved for specific uses:\n",
      "     |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      "     |            whether the `call` is meant for training or inference.\n",
      "     |          * `mask`: Boolean input mask.\n",
      "     |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      "     |          layers do), its default value will be set to the mask generated\n",
      "     |          for `inputs` by the previous layer (if `input` did come from\n",
      "     |          a layer that generated a corresponding mask, i.e. if it came from\n",
      "     |          a Keras layer with masking support.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  add_loss(self, losses, inputs=None)\n",
      "     |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      "     |      \n",
      "     |      Some losses (for instance, activity regularization losses) may be dependent\n",
      "     |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      "     |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      "     |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      "     |      of dependencies.\n",
      "     |      \n",
      "     |      This method can be used inside a subclassed layer or model's `call`\n",
      "     |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      class MyLayer(tf.keras.layers.Layer):\n",
      "     |        def call(inputs, self):\n",
      "     |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      "     |          return inputs\n",
      "     |      ```\n",
      "     |      \n",
      "     |      This method can also be called directly on a Functional Model during\n",
      "     |      construction. In this case, any loss Tensors passed to this Model must\n",
      "     |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      "     |      losses become part of the model's topology and are tracked in `get_config`.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      inputs = tf.keras.Input(shape=(10,))\n",
      "     |      x = tf.keras.layers.Dense(10)(inputs)\n",
      "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
      "     |      model = tf.keras.Model(inputs, outputs)\n",
      "     |      # Actvity regularization.\n",
      "     |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      If this is not the case for your loss (if, for example, your loss references\n",
      "     |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      "     |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      "     |      topology since they can't be serialized.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      inputs = tf.keras.Input(shape=(10,))\n",
      "     |      x = tf.keras.layers.Dense(10)(inputs)\n",
      "     |      outputs = tf.keras.layers.Dense(1)(x)\n",
      "     |      model = tf.keras.Model(inputs, outputs)\n",
      "     |      # Weight regularization.\n",
      "     |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      "     |      specific set of inputs.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      "     |          may also be zero-argument callables which create a loss tensor.\n",
      "     |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      "     |          passed, it signals the losses are conditional on some of the layer's\n",
      "     |          inputs, and thus they should only be run where these inputs are\n",
      "     |          available. This is the case for activity regularization losses, for\n",
      "     |          instance. If `None` is passed, the losses are assumed\n",
      "     |          to be unconditional, and will apply across all dataflows of the layer\n",
      "     |          (e.g. weight regularization losses).\n",
      "     |  \n",
      "     |  add_metric(self, value, aggregation=None, name=None)\n",
      "     |      Adds metric tensor to the layer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: Metric tensor.\n",
      "     |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      "     |          it indicates that the metric tensor provided has been aggregated\n",
      "     |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      "     |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      "     |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      "     |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      "     |          aggregation='mean')`.\n",
      "     |        name: String metric name.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      "     |  \n",
      "     |  add_update(self, updates, inputs=None)\n",
      "     |      Add update op(s), potentially dependent on layer inputs.\n",
      "     |      \n",
      "     |      Weight updates (for instance, the updates of the moving mean and variance\n",
      "     |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      "     |      when calling a layer. Hence, when reusing the same layer on\n",
      "     |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      "     |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      "     |      of dependencies.\n",
      "     |      \n",
      "     |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      "     |      specific set of inputs.\n",
      "     |      \n",
      "     |      This call is ignored when eager execution is enabled (in that case, variable\n",
      "     |      updates are run on the fly and thus do not need to be tracked for later\n",
      "     |      execution).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      "     |          that returns an update op. A zero-arg callable should be passed in\n",
      "     |          order to disable running the updates by setting `trainable=False`\n",
      "     |          on this Layer, when executing in Eager mode.\n",
      "     |        inputs: If anything other than None is passed, it signals the updates\n",
      "     |          are conditional on some of the layer's inputs,\n",
      "     |          and thus they should only be run where these inputs are available.\n",
      "     |          This is the case for BatchNormalization updates, for instance.\n",
      "     |          If None, the updates will be taken into account unconditionally,\n",
      "     |          and you are responsible for making sure that any dependency they might\n",
      "     |          have is available at runtime.\n",
      "     |          A step counter might fall into this category.\n",
      "     |  \n",
      "     |  add_variable(self, *args, **kwargs)\n",
      "     |      Alias for `add_weight`.\n",
      "     |  \n",
      "     |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      "     |      Adds a new variable to the layer.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        name: Variable name.\n",
      "     |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      "     |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      "     |        initializer: initializer instance (callable).\n",
      "     |        regularizer: regularizer instance (callable).\n",
      "     |        trainable: whether the variable should be part of the layer's\n",
      "     |          \"trainable_variables\" (e.g. variables, biases)\n",
      "     |          or \"non_trainable_variables\" (e.g. BatchNorm mean, stddev).\n",
      "     |          Note, if the current variable scope is marked as non-trainable\n",
      "     |          then this parameter is ignored and any added variables are also\n",
      "     |          marked as non-trainable. `trainable` defaults to `True` unless\n",
      "     |          `synchronization` is set to `ON_READ`.\n",
      "     |        constraint: constraint instance (callable).\n",
      "     |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      "     |        use_resource: Whether to use `ResourceVariable`.\n",
      "     |        synchronization: Indicates when a distributed a variable will be\n",
      "     |          aggregated. Accepted values are constants defined in the class\n",
      "     |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "     |          `AUTO` and the current `DistributionStrategy` chooses\n",
      "     |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      "     |          `trainable` must not be set to `True`.\n",
      "     |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      "     |          Accepted values are constants defined in the class\n",
      "     |          `tf.VariableAggregation`.\n",
      "     |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      "     |          `collections`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created variable.  Usually either a `Variable` or `ResourceVariable`\n",
      "     |        instance.  If `partitioner` is not `None`, a `PartitionedVariable`\n",
      "     |        instance is returned.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called with partioned variable regularization and\n",
      "     |          eager execution is enabled.\n",
      "     |        ValueError: When giving unsupported dtype and no initializer or when\n",
      "     |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      "     |  \n",
      "     |  apply(self, inputs, *args, **kwargs)\n",
      "     |      Apply the layer on a input.\n",
      "     |      \n",
      "     |      This is an alias of `self.__call__`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        inputs: Input tensor(s).\n",
      "     |        *args: additional positional arguments to be passed to `self.call`.\n",
      "     |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Output tensor(s).\n",
      "     |  \n",
      "     |  count_params(self)\n",
      "     |      Count the total number of scalars composing the weights.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          An integer count.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: if the layer isn't yet built\n",
      "     |            (in which case its weights aren't yet defined).\n",
      "     |  \n",
      "     |  get_input_at(self, node_index)\n",
      "     |      Retrieves the input tensor(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called in Eager mode.\n",
      "     |  \n",
      "     |  get_input_mask_at(self, node_index)\n",
      "     |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A mask tensor\n",
      "     |          (or list of tensors if the layer has multiple inputs).\n",
      "     |  \n",
      "     |  get_input_shape_at(self, node_index)\n",
      "     |      Retrieves the input shape(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A shape tuple\n",
      "     |          (or list of shape tuples if the layer has multiple inputs).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called in Eager mode.\n",
      "     |  \n",
      "     |  get_losses_for(self, inputs)\n",
      "     |      Retrieves losses relevant to a specific set of inputs.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        inputs: Input tensor or list/tuple of input tensors.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        List of loss tensors of the layer that depend on `inputs`.\n",
      "     |  \n",
      "     |  get_output_at(self, node_index)\n",
      "     |      Retrieves the output tensor(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called in Eager mode.\n",
      "     |  \n",
      "     |  get_output_mask_at(self, node_index)\n",
      "     |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A mask tensor\n",
      "     |          (or list of tensors if the layer has multiple outputs).\n",
      "     |  \n",
      "     |  get_output_shape_at(self, node_index)\n",
      "     |      Retrieves the output shape(s) of a layer at a given node.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          node_index: Integer, index of the node\n",
      "     |              from which to retrieve the attribute.\n",
      "     |              E.g. `node_index=0` will correspond to the\n",
      "     |              first time the layer was called.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A shape tuple\n",
      "     |          (or list of shape tuples if the layer has multiple outputs).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called in Eager mode.\n",
      "     |  \n",
      "     |  get_updates_for(self, inputs)\n",
      "     |      Retrieves updates relevant to a specific set of inputs.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |        inputs: Input tensor or list/tuple of input tensors.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        List of update ops of the layer that depend on `inputs`.\n",
      "     |  \n",
      "     |  set_weights(self, weights)\n",
      "     |      Sets the weights of the layer, from Numpy arrays.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          weights: a list of Numpy arrays. The number\n",
      "     |              of arrays and their shape must match\n",
      "     |              number of the dimensions of the weights\n",
      "     |              of the layer (i.e. it should match the\n",
      "     |              output of `get_weights`).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: If the provided weights list does not match the\n",
      "     |              layer's specifications.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      "     |  \n",
      "     |  activity_regularizer\n",
      "     |      Optional regularizer function for the output of this layer.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  inbound_nodes\n",
      "     |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      "     |  \n",
      "     |  input\n",
      "     |      Retrieves the input tensor(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has exactly one input,\n",
      "     |      i.e. if it is connected to one incoming layer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Input tensor or list of input tensors.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AttributeError: if the layer is connected to\n",
      "     |          more than one incoming layers.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called in Eager mode.\n",
      "     |        AttributeError: If no inbound nodes are found.\n",
      "     |  \n",
      "     |  input_mask\n",
      "     |      Retrieves the input mask tensor(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has exactly one inbound node,\n",
      "     |      i.e. if it is connected to one incoming layer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Input mask tensor (potentially None) or list of input\n",
      "     |          mask tensors.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AttributeError: if the layer is connected to\n",
      "     |          more than one incoming layers.\n",
      "     |  \n",
      "     |  input_shape\n",
      "     |      Retrieves the input shape(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has exactly one input,\n",
      "     |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      "     |      have the same shape.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Input shape, as an integer shape tuple\n",
      "     |          (or list of shape tuples, one tuple per input tensor).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AttributeError: if the layer has no defined input_shape.\n",
      "     |          RuntimeError: if called in Eager mode.\n",
      "     |  \n",
      "     |  losses\n",
      "     |      Losses which are associated with this `Layer`.\n",
      "     |      \n",
      "     |      Variable regularization tensors are created when this property is accessed,\n",
      "     |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      "     |      propagate gradients back to the corresponding variables.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of tensors.\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  non_trainable_variables\n",
      "     |  \n",
      "     |  outbound_nodes\n",
      "     |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      "     |  \n",
      "     |  output\n",
      "     |      Retrieves the output tensor(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has exactly one output,\n",
      "     |      i.e. if it is connected to one incoming layer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Output tensor or list of output tensors.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        AttributeError: if the layer is connected to more than one incoming\n",
      "     |          layers.\n",
      "     |        RuntimeError: if called in Eager mode.\n",
      "     |  \n",
      "     |  output_mask\n",
      "     |      Retrieves the output mask tensor(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has exactly one inbound node,\n",
      "     |      i.e. if it is connected to one incoming layer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Output mask tensor (potentially None) or list of output\n",
      "     |          mask tensors.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AttributeError: if the layer is connected to\n",
      "     |          more than one incoming layers.\n",
      "     |  \n",
      "     |  output_shape\n",
      "     |      Retrieves the output shape(s) of a layer.\n",
      "     |      \n",
      "     |      Only applicable if the layer has one output,\n",
      "     |      or if all outputs have the same shape.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Output shape, as an integer shape tuple\n",
      "     |          (or list of shape tuples, one tuple per output tensor).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AttributeError: if the layer has no defined output shape.\n",
      "     |          RuntimeError: if called in Eager mode.\n",
      "     |  \n",
      "     |  trainable\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of variables owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  updates\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Returns the list of all layer variables/weights.\n",
      "     |      \n",
      "     |      Alias of `self.weights`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  with_name_scope(method) from builtins.type\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      ```\n",
      "     |      class MyModule(tf.Module):\n",
      "     |        @tf.Module.with_name_scope\n",
      "     |        def __call__(self, x):\n",
      "     |          if not hasattr(self, 'w'):\n",
      "     |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      "     |          return tf.matmul(x, self.w)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      mod = MyModule()\n",
      "     |      mod(tf.ones([8, 32]))\n",
      "     |      # ==> <tf.Tensor: ...>\n",
      "     |      mod.w\n",
      "     |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      ```\n",
      "     |      a = tf.Module()\n",
      "     |      b = tf.Module()\n",
      "     |      c = tf.Module()\n",
      "     |      a.b = b\n",
      "     |      b.c = c\n",
      "     |      assert list(a.submodules) == [b, c]\n",
      "     |      assert list(b.submodules) == [c]\n",
      "     |      assert list(c.submodules) == []\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    Input(shape=None, batch_size=None, name=None, dtype=None, sparse=False, tensor=None, **kwargs)\n",
      "        `Input()` is used to instantiate a Keras tensor.\n",
      "        \n",
      "        A Keras tensor is a tensor object from the underlying backend\n",
      "        (Theano or TensorFlow), which we augment with certain\n",
      "        attributes that allow us to build a Keras model\n",
      "        just by knowing the inputs and outputs of the model.\n",
      "        \n",
      "        For instance, if a, b and c are Keras tensors,\n",
      "        it becomes possible to do:\n",
      "        `model = Model(input=[a, b], output=c)`\n",
      "        \n",
      "        The added Keras attribute is:\n",
      "            `_keras_history`: Last layer applied to the tensor.\n",
      "                the entire layer graph is retrievable from that layer,\n",
      "                recursively.\n",
      "        \n",
      "        Arguments:\n",
      "            shape: A shape tuple (integers), not including the batch size.\n",
      "                For instance, `shape=(32,)` indicates that the expected input\n",
      "                will be batches of 32-dimensional vectors.\n",
      "            batch_size: optional static batch size (integer).\n",
      "            name: An optional name string for the layer.\n",
      "                Should be unique in a model (do not reuse the same name twice).\n",
      "                It will be autogenerated if it isn't provided.\n",
      "            dtype: The data type expected by the input, as a string\n",
      "                (`float32`, `float64`, `int32`...)\n",
      "            sparse: A boolean specifying whether the placeholder\n",
      "                to be created is sparse.\n",
      "            tensor: Optional existing tensor to wrap into the `Input` layer.\n",
      "                If set, the layer will not create a placeholder tensor.\n",
      "            **kwargs: deprecated arguments support.\n",
      "        \n",
      "        Returns:\n",
      "          A `tensor`.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        # this is a logistic regression in Keras\n",
      "        x = Input(shape=(32,))\n",
      "        y = Dense(16, activation='softmax')(x)\n",
      "        model = Model(x, y)\n",
      "        ```\n",
      "        \n",
      "        Note that even if eager execution is enabled,\n",
      "        `Input` produces a symbolic tensor (i.e. a placeholder).\n",
      "        This symbolic tensor can be used with other\n",
      "        TensorFlow ops, as such:\n",
      "        \n",
      "        ```python\n",
      "        x = Input(shape=(32,))\n",
      "        y = tf.square(x)\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: in case of invalid arguments.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Input', 'Model', 'Sequential', '__builtins__', '__cached__...\n",
      "\n",
      "VERSION\n",
      "    2.2.4-tf\n",
      "\n",
      "FILE\n",
      "    c:\\anaconda\\envs\\test3\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v1\\keras\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    \n",
    "# 1.  \n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y_ori = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_origin  \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y_ori, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ,  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 2.    \n",
    "#  8,  1,  3  \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=8, # 8 ()\n",
    "                input_dim=4, # 4 (- &)\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.    \n",
    "model.compile(loss='categorical_crossentropy', #  \n",
    "              optimizer='adam', #  \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda\\envs\\test3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      " - 0s - loss: 1.1060 - accuracy: 0.3143\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.0633 - accuracy: 0.4095\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.0244 - accuracy: 0.6952\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.9660 - accuracy: 0.6952\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.8795 - accuracy: 0.6952\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.7901 - accuracy: 0.6952\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.7045 - accuracy: 0.6952\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.6252 - accuracy: 0.7333\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.5732 - accuracy: 0.7429\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.5254 - accuracy: 0.7429\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4822 - accuracy: 0.8095\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.4527 - accuracy: 0.8762\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4272 - accuracy: 0.8381\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4076 - accuracy: 0.8762\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.3847 - accuracy: 0.9048\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.3676 - accuracy: 0.9333\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.3561 - accuracy: 0.9048\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.3347 - accuracy: 0.9048\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.3227 - accuracy: 0.9429\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.3109 - accuracy: 0.9619\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2986 - accuracy: 0.9619\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2938 - accuracy: 0.9143\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2685 - accuracy: 0.9714\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2644 - accuracy: 0.9524\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2589 - accuracy: 0.9524\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.2504 - accuracy: 0.9810\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.2374 - accuracy: 0.9619\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2361 - accuracy: 0.9619\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.2230 - accuracy: 0.9619\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.2099 - accuracy: 0.9905\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.2101 - accuracy: 0.9714\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.2030 - accuracy: 0.9619\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1907 - accuracy: 0.9714\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1954 - accuracy: 0.9619\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.1853 - accuracy: 0.9714\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1800 - accuracy: 0.9619\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1743 - accuracy: 0.9619\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1708 - accuracy: 0.9714\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1653 - accuracy: 0.9619\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1616 - accuracy: 0.9619\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1600 - accuracy: 0.9714\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1547 - accuracy: 0.9714\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1496 - accuracy: 0.9524\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1487 - accuracy: 0.9619\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.1435 - accuracy: 0.9714\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.1482 - accuracy: 0.9619\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.1353 - accuracy: 0.9810\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.1356 - accuracy: 0.9619\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.1341 - accuracy: 0.9714\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.1323 - accuracy: 0.9619\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.1297 - accuracy: 0.9524\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.1259 - accuracy: 0.9524\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.1233 - accuracy: 0.9619\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.1222 - accuracy: 0.9714\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.1202 - accuracy: 0.9619\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.1194 - accuracy: 0.9619\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.1141 - accuracy: 0.9524\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.1140 - accuracy: 0.9714\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.1147 - accuracy: 0.9524\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.1060 - accuracy: 0.9619\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.1144 - accuracy: 0.9714\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.1039 - accuracy: 0.9714\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.1070 - accuracy: 0.9619\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.1027 - accuracy: 0.9524\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.1041 - accuracy: 0.9714\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.1011 - accuracy: 0.9619\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.1006 - accuracy: 0.9714\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0974 - accuracy: 0.9524\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.1028 - accuracy: 0.9619\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0964 - accuracy: 0.9714\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0998 - accuracy: 0.9714\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0963 - accuracy: 0.9714\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0924 - accuracy: 0.9619\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0983 - accuracy: 0.9429\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0943 - accuracy: 0.9524\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0909 - accuracy: 0.9619\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0909 - accuracy: 0.9714\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0902 - accuracy: 0.9619\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0865 - accuracy: 0.9714\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0869 - accuracy: 0.9619\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0849 - accuracy: 0.9619\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0887 - accuracy: 0.9619\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0774 - accuracy: 0.9810\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0868 - accuracy: 0.9714\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0807 - accuracy: 0.9714\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0845 - accuracy: 0.9714\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0815 - accuracy: 0.9714\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0817 - accuracy: 0.9524\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0797 - accuracy: 0.9714\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0775 - accuracy: 0.9810\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0761 - accuracy: 0.9714\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0806 - accuracy: 0.9619\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0784 - accuracy: 0.9810\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0721 - accuracy: 0.9714\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0816 - accuracy: 0.9714\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0790 - accuracy: 0.9619\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0710 - accuracy: 0.9714\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0840 - accuracy: 0.9714\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0771 - accuracy: 0.9619\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0761 - accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aea4b5f88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.  \n",
    "model.fit(X_train, y_train,\n",
    "          epochs=100, # 100\n",
    "          batch_size=1, #  1\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history    \n",
    "hist = model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9714286,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.96190476,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 1.0,\n",
       " 0.96190476,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.96190476,\n",
       " 0.9904762,\n",
       " 0.9809524,\n",
       " 0.96190476,\n",
       " 0.9714286,\n",
       " 0.95238096,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.96190476,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.96190476,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.96190476,\n",
       " 0.9714286,\n",
       " 0.96190476,\n",
       " 0.9904762,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9904762,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.96190476,\n",
       " 0.9904762,\n",
       " 0.96190476,\n",
       " 0.96190476,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9809524,\n",
       " 0.9714286,\n",
       " 0.9809524,\n",
       " 0.9809524]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05820176502374784,\n",
       " 0.05622834466145191,\n",
       " 0.06350488387715969,\n",
       " 0.06368020409479049,\n",
       " 0.05395763192711512,\n",
       " 0.053611148382877345,\n",
       " 0.05311466454927479,\n",
       " 0.05206928371836434,\n",
       " 0.0557269579101651,\n",
       " 0.06013162084273354,\n",
       " 0.050117353121211274,\n",
       " 0.05377237415216388,\n",
       " 0.05110243081428142,\n",
       " 0.04831016417950031,\n",
       " 0.055404691606313505,\n",
       " 0.05874858135838834,\n",
       " 0.05072616903029318,\n",
       " 0.050758781097524554,\n",
       " 0.05580008504215769,\n",
       " 0.04669635413836184,\n",
       " 0.03848085685855084,\n",
       " 0.05539930324629883,\n",
       " 0.04962930810623943,\n",
       " 0.05468590453983732,\n",
       " 0.054407465998321566,\n",
       " 0.05545239223482552,\n",
       " 0.05160343237132295,\n",
       " 0.05532556339226453,\n",
       " 0.058948893088300536,\n",
       " 0.04781275767922033,\n",
       " 0.05991112883222167,\n",
       " 0.054057317284632034,\n",
       " 0.0532793539328858,\n",
       " 0.050055327796030995,\n",
       " 0.05122512381746506,\n",
       " 0.05251323126940142,\n",
       " 0.05504807709878497,\n",
       " 0.05785256169055467,\n",
       " 0.04475172352085312,\n",
       " 0.057784131749178666,\n",
       " 0.053290510448783565,\n",
       " 0.05473522352425582,\n",
       " 0.06151074116960736,\n",
       " 0.054131460560475846,\n",
       " 0.05490866703012189,\n",
       " 0.05057780515748031,\n",
       " 0.053657333743459004,\n",
       " 0.04956802506033846,\n",
       " 0.051100616513039245,\n",
       " 0.0504266425173321,\n",
       " 0.04940069961475811,\n",
       " 0.05463564417507787,\n",
       " 0.052993725122678234,\n",
       " 0.04351240985794139,\n",
       " 0.0680141926167554,\n",
       " 0.04856482510245908,\n",
       " 0.04961173537066041,\n",
       " 0.05279328141969789,\n",
       " 0.05450685848224385,\n",
       " 0.051719023352417605,\n",
       " 0.04680498199121956,\n",
       " 0.048479780594675705,\n",
       " 0.05679201524489316,\n",
       " 0.05219165670127787,\n",
       " 0.047821973690764435,\n",
       " 0.04750226483464578,\n",
       " 0.05269357216895651,\n",
       " 0.04202240828140081,\n",
       " 0.054242957936945876,\n",
       " 0.05608497995797299,\n",
       " 0.05001692737567788,\n",
       " 0.05314888698669857,\n",
       " 0.05054032945096934,\n",
       " 0.04524639538945731,\n",
       " 0.0515334705824137,\n",
       " 0.06262893709503736,\n",
       " 0.06466769821662763,\n",
       " 0.05474540156589955,\n",
       " 0.05105306066228934,\n",
       " 0.047555967693830255,\n",
       " 0.04778754014043282,\n",
       " 0.04959550866189867,\n",
       " 0.04871298869169634,\n",
       " 0.047111445192455005,\n",
       " 0.05314349097420677,\n",
       " 0.04681444671440452,\n",
       " 0.046489482376974645,\n",
       " 0.05169007822628163,\n",
       " 0.05356285580450035,\n",
       " 0.051851934015857366,\n",
       " 0.05457799639925041,\n",
       " 0.04686554670078094,\n",
       " 0.04562550179559672,\n",
       " 0.05103955253354731,\n",
       " 0.05413701665948573,\n",
       " 0.05082948549722989,\n",
       " 0.04732285823098572,\n",
       " 0.055115977041800907,\n",
       " 0.048961121045067356,\n",
       " 0.04716321141922065]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 888us/step\n"
     ]
    }
   ],
   "source": [
    "# 5.   \n",
    "loss, acc = model.evaluate(X_test, y_test) # , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 0.084\n",
      ": 0.978\n"
     ]
    }
   ],
   "source": [
    "print(\":\", round(loss, 3))\n",
    "print(\":\", round(acc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.84 2.24 5.5  4.71]\n",
      " [4.75 3.37 2.91 6.35]\n",
      " [5.8  1.1  0.01 0.68]]\n"
     ]
    }
   ],
   "source": [
    "# 6.     \n",
    "from numpy.random import random\n",
    "from numpy import round\n",
    "\n",
    "X_new = round(random([3,4]) * 10, 2)\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = model.predict_classes(X_new)\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\test3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data\n",
    "y_ori = mnist.target.astype(np.int)\n",
    "y = to_categorical(y_ori, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=20, activation='relu'))\n",
    "model.add(Dense(units=15, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.001), # optimizer='adam'\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49000 samples, validate on 21000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 3.2532 - accuracy: 0.2910 - val_loss: 1.6515 - val_accuracy: 0.3948\n",
      "Epoch 2/10\n",
      " - 3s - loss: 1.4649 - accuracy: 0.4816 - val_loss: 1.2171 - val_accuracy: 0.6259\n",
      "Epoch 3/10\n",
      " - 3s - loss: 1.0011 - accuracy: 0.6891 - val_loss: 0.8692 - val_accuracy: 0.7291\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.7809 - accuracy: 0.7653 - val_loss: 0.7426 - val_accuracy: 0.7805\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.6537 - accuracy: 0.8173 - val_loss: 0.6303 - val_accuracy: 0.8261\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.5724 - accuracy: 0.8439 - val_loss: 0.5870 - val_accuracy: 0.8486\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.5237 - accuracy: 0.8583 - val_loss: 0.5343 - val_accuracy: 0.8570\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.4801 - accuracy: 0.8659 - val_loss: 0.5216 - val_accuracy: 0.8561\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.4458 - accuracy: 0.8756 - val_loss: 0.4779 - val_accuracy: 0.8719\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.4194 - accuracy: 0.8847 - val_loss: 0.4639 - val_accuracy: 0.8784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aea908908>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=100, verbose=2,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 1s 33us/step\n",
      "0.46392944777863365\n",
      "0.8783809542655945\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(loss)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "# y_ori => 2\n",
    "# y => [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "#       0  1  2  3  4  5  6  7  8  9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1908    0   17    2    2   20   62   19   44    2]\n",
      " [   2 2234   45    4    2    3   16   11   65    8]\n",
      " [  10    3 1806    8   27   11  129   17  108    5]\n",
      " [   1    2   49 1787    4  119   15   47  115   26]\n",
      " [   3    5   15    0 1817    2   40   11    5  165]\n",
      " [  28    4   26   72    9 1690   19   19   32   24]\n",
      " [  30    3   72    0   10   24 1848    5    4    3]\n",
      " [   4    1    7    5    3    9   15 1964   33  115]\n",
      " [   8    5  142    4    7   54   22   42 1730   34]\n",
      " [   6    2    3   22  161   21    9  150   20 1662]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = 'adams'  'sgd', 'rmsprop'\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SGD in module keras.optimizers:\n",
      "\n",
      "class SGD(Optimizer)\n",
      " |  SGD(learning_rate=0.01, momentum=0.0, nesterov=False, **kwargs)\n",
      " |  \n",
      " |  Stochastic gradient descent optimizer.\n",
      " |  \n",
      " |  Includes support for momentum,\n",
      " |  learning rate decay, and Nesterov momentum.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      learning_rate: float >= 0. Learning rate.\n",
      " |      momentum: float >= 0. Parameter that accelerates SGD\n",
      " |          in the relevant direction and dampens oscillations.\n",
      " |      nesterov: boolean. Whether to apply Nesterov momentum.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SGD\n",
      " |      Optimizer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, learning_rate=0.01, momentum=0.0, nesterov=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |  \n",
      " |  get_updates(self, loss, params)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Optimizer:\n",
      " |  \n",
      " |  get_gradients(self, loss, params)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current value of the weights of the optimizer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the optimizer, from Numpy arrays.\n",
      " |      \n",
      " |      Should only be called after computing the gradients\n",
      " |      (otherwise the optimizer has no weights).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the optimizer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of incompatible weight shapes.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from Optimizer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Optimizer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  lr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test3",
   "language": "python",
   "name": "test3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
